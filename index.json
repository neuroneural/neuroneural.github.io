[{"categories":["Classes"],"contents":"Machine learning studies algorithms that build models from data for subsequent use in prediction, inference, and decision making tasks. Although an active field for the last 60 years, the current demand as well as trust in machine learning exploded as increasingly more data become available and the problems needed to be addressed become literally impossible to program directly. In this advanced course we will cover essential algorithms, concepts, and principles of machine learning. Along with the traditional exposition we will learn how these principles are currently being revisited thanks to the recent discoveries in the field.\n1. Introduction Lecture Slides Youtube Lectures Introductions 7:51 Why Machine Learning 12:00 What is Machine Learning 18:57 History of Machine Learning 17:33 Reinforcement Learning 10:32 Course Overview 19:26 The Project 20:03 2. Foundations of learning Lecture Slides Youtube Lectures Formalizing the Problem of Learning 24:19 Inductive Bias 12:03 Can We Bound the Probability of Error? 25:56 3. PAC learnability Lecture Slides Youtube Lectures Main Definitions from Lecture 2 13:52 Agnostic PAC Learning 53:35 Learning via Uniform Convergence 10:15 4. Linear algebra and Optimization (recap) 3Blue1Brown Playlist 5. Linear learning models Lecture Slides Youtube Lectures Linear Decision Boundary 34:10 Perceptron 37:10 Perceptron Extensions 14:09 Linear Classifier for Linearly non Separable Classes 8:59 6. Principal Component Analysis Lecture Slides Youtube lectures Linear Regression 39:24 Linear Algebra Micro Refresher 2:04 Spectral Theorem 25:54 Principal Component Analysis 22:29 Demonstration 17:38 7. Curse of Dimensionality Lecture Slides Youtube lectures Curse of Dimensionality 1:16:27 8. Bayesian Decision Theory Lecture Slides Youtube lectures Bayesian Decision Theory 56:47 9. Parameter estimation: MLE Lecture Slides Youtube Lectures Independence 12:07 Maximum Likelihood Estimation 50:35 MLE as KL-divergence minimization 21:41 10. Parameter estimation: MAP \u0026amp; Naïve Bayes Lecture Slides Youtube Lectures MAP Estimation 56:00 The Naïve Bayes Classifier 37:09 11. Logistic Regression Lecture Slides Youtube Lectures NB to LR 19:49 Defining Logistic Regression 27:42 Solving Logistic Regression 23:35 12. Kernel Density Estimation Lecture Slides Youtube Lectures Non-parametric Density Estimation 1:13:33 13. Support Vector Machines Lecture Slides Youtube Lectures Max Margin Classifier 35:53 Lagrange Multipliers 32:45 Dual Formulation of Linear SVM 10:34 Kernel Trick and Soft Margin 27:28 14. Matrix Factorization Lecture Slides Youtube Lectures Matrix Factorization 1:24:22 15. Stochastic Gradient Descent Lecture Slides Youtube Lectures Stochastic Gradient Descent 1:06:57 16. k-means Clustering Lecture Slides Youtube Lectures Clustering 6:05 Gaussian Mixture Models 16:34 MLE recap 4:20 Hard k-means Clustering 30:27 Soft k-means Clustering 7:18 17. Expectation Maximization Lecture Slides Youtube Lectures Do we even need EM for GMM? 14:39 A \u0026ldquo;hacky\u0026rdquo; GMM estimation 15:17 MLE via EM 38:28 18. Automatic Differentiation Lecture Slides Youtube Lectures Introduction 25:10 Forward Mode AD 26:46 A minute of Backprop 2:26 Reverse mode AD 17:26 19. Nonlinear Embedding Approaches Lecture Slides Youtube Lectures Manifold Learning 20:13 20. Model Comparison I Lecture Slides Youtube Lectures Bias Variance Trade-Off 36:52 No Free Lunch Theorem 7:29 Problems with using accuracy as performance indicator 12:39 Confusion Matrix 25:15 21. Model Comparison II Lecture Slides Youtube Lectures Cross validation and hyperopt 29:08 Expected Value Framework 22:48 Visualizing Model Performance 1 31:02 Receiver Operating Characteristics 22:34 22. Model Calibration Lecture Slides Youtube Lectures On Model Calibration 36:53 23. Convolutional Neural Networks Lecture Slides Youtube Lectures Building Blocks 39:22 Skip Connection 38:46 Fully Convolutional Networks 8:07 Semantic Segmentation with Twists 23:40 Special Convolutions 20:15 24. Word Embedding Lecture Slides Youtube Lectures Introduction 10:35 Semantic Matrix 30:26 word2vec 54:22 ","permalink":"http://localhost:1313/posts/advancedml/","tags":null,"title":"Advanced Machine Learning"},{"categories":["Publications"],"contents":"Authors : Kseniya Solovyeva, David Danks, Mohammadsajad Abavisani, Sergey Plis\nPublication date : 2023/2/20\nJournal : Proceedings of Machine Learning Research\nVolume : 13\nIssue :\nPages :\nPublisher : Cambridge MA: JMLR\nDescription\nDomain scientists interested in causal mechanisms are usually limited by the frequency at which they can collect the measurements of social, physical, or biological systems. A common and plausible assumption is that higher measurement frequencies are the only way to gain more informative data about the underlying dynamical causal structure. This assumption is a strong driver for designing new, faster instruments, but such instruments might not be feasible or even possible. In this paper, we show that this assumption is incorrect: there are situations in which we can gain additional information about the causal structure by measuring more than our current instruments. We present an algorithm that uses graphs at multiple measurement timescales to infer underlying causal structure, and show that inclusion of structures at slower timescales can nonetheless reduce the size of the equivalence class of possible causal structures. We provide simulation data about the probability of cases in which deliberate undersampling yields a gain, as well as the size of this gain.\nView article\n","permalink":"http://localhost:1313/posts/causal-learning-through-deliberate-undersampling/","tags":["Paper","Publications"],"title":"Causal Learning through Deliberate Undersampling"},{"categories":["Publications"],"contents":"Authors : Alex Fedorov, Eloy Geenjaar, Lei Wu, Tristan Sylvain, Thomas P DeRamus, Margaux Luck, Maria Misiura, R Devon Hjelm, Sergey M Plis, Vince D Calhoun\nPublication date : 2022/9/7\nJournal : arXiv preprint arXiv:2209.02876\nDescription\nRecent neuroimaging studies that focus on predicting brain disorders via modern machine learning approaches commonly include a single modality and rely on supervised over-parameterized models.However, a single modality provides only a limited view of the highly complex brain. Critically, supervised models in clinical settings lack accurate diagnostic labels for training. Coarse labels do not capture the long-tailed spectrum of brain disorder phenotypes, which leads to a loss of generalizability of the model that makes them less useful in diagnostic settings. This work presents a novel multi-scale coordinated framework for learning multiple representations from multimodal neuroimaging data. We propose a general taxonomy of informative inductive biases to capture unique and joint information in multimodal self-supervised fusion. The taxonomy forms a family of decoder-free models with reduced computational complexity and a propensity to capture multi-scale relationships between local and global representations of the multimodal inputs. We conduct a comprehensive evaluation of the taxonomy using functional and structural magnetic resonance imaging (MRI) data across a spectrum of Alzheimer\u0026rsquo;s disease phenotypes and show that self-supervised models reveal disorder-relevant brain regions and multimodal links without access to the labels during pre-training. The proposed multimodal self-supervised learning yields representations with improved classification performance for both modalities. The concomitant rich and flexible unsupervised deep learning framework captures complex multimodal relationships and provides predictive …\nView article\n","permalink":"http://localhost:1313/posts/self-supervised-multimodal-neuroimaging-yields-predictive-representations-for-a-spectrum-of-alzheimers-phenotypes/","tags":["Paper","Publications"],"title":"Self-supervised multimodal neuroimaging yields predictive representations for a spectrum of Alzheimer's phenotypes"},{"categories":["Publications"],"contents":"Authors : Xinhui Li, Alex Fedorov, Mrinal Mathur, Anees Abrol, Gregory Kiar, Sergey Plis, Vince Calhoun\nPublication date : 2022/8/27\nJournal : arXiv preprint arXiv:2208.12909\nDescription\nDeep learning has been widely applied in neuroimaging, including to predicting brain-phenotype relationships from magnetic resonance imaging (MRI) volumes. MRI data usually requires extensive preprocessing before it is ready for modeling, even via deep learning, in part due to its high dimensionality and heterogeneity. A growing array of MRI preprocessing pipelines have been developed each with its own strengths and limitations. Recent studies have shown that pipeline-related variation may lead to different scientific findings, even when using the identical data. Meanwhile, the machine learning community has emphasized the importance of shifting from model-centric to data-centric approaches given that data quality plays an essential role in deep learning applications. Motivated by this idea, we first evaluate how preprocessing pipeline selection can impact the downstream performance of a supervised learning model. We next propose two pipeline-invariant representation learning methodologies, MPSL and PXL, to improve consistency in classification performance and to capture similar neural network representations between pipeline pairs. Using 2000 human subjects from the UK Biobank dataset, we demonstrate that both models present unique advantages, in particular that MPSL can be used to improve out-of-sample generalization to new pipelines, while PXL can be used to improve predictive performance consistency and representational similarity within a closed pipeline set. These results suggest that our proposed models can be applied to overcome pipeline-related biases and to improve reproducibility in neuroimaging …\nView article\n","permalink":"http://localhost:1313/posts/pipeline-invariant-representation-learning-for-neuroimaging/","tags":["Paper","Publications"],"title":"Pipeline-Invariant Representation Learning for Neuroimaging"},{"categories":["Publications"],"contents":"Authors : Md Rahman, Usman Mahmood, Noah Lewis, Harshvardhan Gazula, Alex Fedorov, Zening Fu, Vince D Calhoun, Sergey M Plis\nPublication date : 2022/7/21\nJournal : Scientific reports\nVolume : 12\nIssue : 1\nPages : 1-15\nPublisher : Nature Publishing Group\nDescription\nBrain dynamics are highly complex and yet hold the key to understanding brain function and dysfunction. The dynamics captured by resting-state functional magnetic resonance imaging data are noisy, high-dimensional, and not readily interpretable. The typical approach of reducing this data to low-dimensional features and focusing on the most predictive features comes with strong assumptions and can miss essential aspects of the underlying dynamics. In contrast, introspection of discriminatively trained deep learning models may uncover disorder-relevant elements of the signal at the level of individual time points and spatial locations. Yet, the difficulty of reliable training on high-dimensional low sample size datasets and the unclear relevance of the resulting predictive markers prevent the widespread use of deep learning in functional neuroimaging. In this work, we introduce a deep learning framework to learn …\nView article\n","permalink":"http://localhost:1313/posts/interpreting-models-interpreting-brain-dynamics/","tags":["Paper","Publications"],"title":"Interpreting models interpreting brain dynamics"},{"categories":["Publications"],"contents":"Authors : Xinhui Li, Eloy Geenjaar, Zening Fu, Sergey Plis, Vince Calhoun\nPublication date : 2022/7/11\nConference : 2022 44th Annual International Conference of the IEEE Engineering in Medicine \u0026amp; Biology Society (EMBC)\nPages : 1477-1480\nPublisher : IEEE\nDescription\nMental disorders such as schizophrenia have been challenging to characterize due in part to their heterogeneous presentation in individuals. Most studies have focused on identifying groups differences and have typically ignored the heterogeneous patterns within groups. Here we propose a novel approach based on a variational autoencoder (VAE) to interpolate static functional network connectivity (sFNC) across individuals, with group-specific patterns between schizophrenia patients and controls captured simultaneously. We then visualize the original sFNC in a 2D grid according to the samples in the VAE latent space. We observe a high correspondence between the generated and the original sFNC. The proposed framework facilitates data visualization and can potentially be applied to predict the stage that a subject falls within a disorder continuum as well as characterize individual heterogeneity within and …\nView article\n","permalink":"http://localhost:1313/posts/mind-the-gap-functional-network-connectivity-interpolation-between-schizophrenia-patients-and-controls-using-a-variational-autoencoder/","tags":["Paper","Publications"],"title":"Mind the gap: functional network connectivity interpolation between schizophrenia patients and controls using a variational autoencoder"},{"categories":["Publications"],"contents":"Authors : Md Mahfuzur Rahman, Noah Lewis, Sergey Plis\nPublication date : 2022/6\nJournal : arXiv e-prints\nPages : arXiv: 2206.05903\nPublisher : Oxford University Press\nDescription\nInterpretability methods for deep neural networks mainly focus on the sensitivity of the class score with respect to the original or perturbed input, usually measured using actual or modified gradients. Some methods also use a model-agnostic approach to understanding the rationale behind every prediction. In this paper, we argue and demonstrate that local geometry of the model parameter space relative to the input can also be beneficial for improved post-hoc explanations. To achieve this goal, we introduce an interpretability method called\u0026quot; geometrically-guided integrated gradients\u0026quot; that builds on top of the gradient calculation along a linear path as traditionally used in integrated gradient methods. However, instead of integrating gradient information, our method explores the model\u0026rsquo;s dynamic behavior from multiple scaled versions of the input and captures the best possible attribution for each input. We …\nView article\n","permalink":"http://localhost:1313/posts/geometrically-guided-integrated-gradients/","tags":["Paper","Publications"],"title":"Geometrically Guided Integrated Gradients"},{"categories":["Publications"],"contents":"Authors : Md Abdur Rahaman, Eswar Damaraju, Debbrata K Saha, Sergey M Plis, Vince D Calhoun\nPublication date : 2022/6/1\nJournal : Human Brain Mapping\nVolume : 43\nIssue : 8\nPages : 2503-2518\nPublisher : John Wiley \u0026amp; Sons, Inc.\nDescription\nDynamic functional network connectivity (dFNC) analysis is a widely used approach for capturing brain activation patterns, connectivity states, and network organization. However, a typical sliding window plus clustering (SWC) approach for analyzing dFNC models the system through a fixed sequence of connectivity states. SWC assumes connectivity patterns span throughout the brain, but they are relatively spatially constrained and temporally short‐lived in practice. Thus, SWC is neither designed to capture transient dynamic changes nor heterogeneity across subjects/time. We propose a state‐space time series summarization framework called “statelets” to address these shortcomings. It models functional connectivity dynamics at fine‐grained timescales, adapting time series motifs to changes in connectivity strength, and constructs a concise yet informative representation of the original data that conveys easily …\nView article\n","permalink":"http://localhost:1313/posts/statelets-capturing-recurrent-transient-variations-in-dynamic-functional-network-connectivity/","tags":["Paper","Publications"],"title":"Statelets: Capturing recurrent transient variations in dynamic functional network connectivity"},{"categories":["Publications"],"contents":"Authors : Mohammadsajad Abavisani, David Danks, Sergey Plis\nPublication date : 2022/5/18\nJournal : arXiv preprint arXiv:2205.09235\nDescription\nGraphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Although this problem has been recently recognized, practitioners have limited resources to respond to it, and so must continue using models that they know are likely misleading. Existing methods either (a) require that the difference between causal and measurement timescales is known; or (b) can handle only very small number of random variables when the timescale difference is unknown; or (c) apply to only pairs of variables, though with fewer assumptions about prior knowledge; or (d) return impractically too many solutions. This paper addresses all four challenges. We combine constraint programming with both theoretical insights into the problem structure and prior information about admissible causal interactions. The resulting system provides a practical approach that scales to significantly larger sets (\u0026gt;100) of random variables, does not require precise knowledge of the timescale difference, supports edge misidentification and parametric connection strengths, and can provide the optimum choice among many possible solutions. The cumulative impact of these improvements is gain of multiple orders of magnitude in speed and informativeness.\nView article\n","permalink":"http://localhost:1313/posts/constraint-based-causal-structure-learning-from-undersampled-graphs/","tags":["Paper","Publications"],"title":"Constraint-Based Causal Structure Learning from Undersampled Graphs"},{"categories":["Publications"],"contents":"Authors : Debbrata K Saha, Vince D Calhoun, Yuhui Du, Zening Fu, Soo Min Kwon, Anand D Sarwate, Sandeep R Panta, Sergey M Plis\nPublication date : 2022/5/1\nJournal : Human Brain Mapping\nVolume : 43\nIssue : 7\nPages : 2289-2310\nPublisher : John Wiley \u0026amp; Sons, Inc.\nDescription\nPrivacy concerns for rare disease data, institutional or IRB policies, access to local computational or storage resources or download capabilities are among the reasons that may preclude analyses that pool data to a single site. A growing number of multisite projects and consortia were formed to function in the federated environment to conduct productive research under constraints of this kind. In this scenario, a quality control tool that visualizes decentralized data in its entirety via global aggregation of local computations is especially important, as it would allow the screening of samples that cannot be jointly evaluated otherwise. To solve this issue, we present two algorithms: decentralized data stochastic neighbor embedding, dSNE, and its differentially private counterpart, DP‐dSNE. We leverage publicly available datasets to simultaneously map data samples located at different sites according to their similarities …\nView article\n","permalink":"http://localhost:1313/posts/privacypreserving-quality-control-of-neuroimaging-datasets-in-federated-environments/","tags":["Paper","Publications"],"title":"Privacy‐preserving quality control of neuroimaging datasets in federated environments"},{"categories":["Publications"],"contents":"Authors : Sunitha Basodi, Rajikha Raja, Bhaskar Ray, Harshvardhan Gazula, Anand D Sarwate, Sergey Plis, Jingyu Liu, Eric Verner, Vince D Calhoun\nPublication date : 2022/4/5\nJournal : Neuroinformatics\nPages : 1-10\nPublisher : Springer US\nDescription\nRecent studies have demonstrated that neuroimaging data can be used to estimate biological brain age, as it captures information about the neuroanatomical and functional changes the brain undergoes during development and the aging process. However, researchers often have limited access to neuroimaging data because of its challenging and expensive acquisition process, thereby limiting the effectiveness of the predictive model. Decentralized models provide a way to build more accurate and generalizable prediction models, bypassing the traditional data-sharing methodology. In this work, we propose a decentralized method for biological brain age estimation using support vector regression models and evaluate it on three different feature sets, including both volumetric and voxelwise structural MRI data as well as resting functional MRI data. The results demonstrate that our decentralized brain age …\nView article\n","permalink":"http://localhost:1313/posts/decentralized-brain-age-estimation-using-mri-data/","tags":["Paper","Publications"],"title":"Decentralized Brain Age Estimation using MRI Data"},{"categories":["Publications"],"contents":"Authors : Elena A Allen, Eswar Damaraju, Sergey M Plis, Erik B Erhardt, Tom Eichele, Vince D Calhoun\nPublication date : 2022/4\nJournal : The Journal of the Astronautical Sciences\nVolume : 69\nIssue : 2\nPages : 570-580\nPublisher : Springer US\nDescription\nThe harsh space environment at geosynchronous orbit (GEO) induces differential charging of spacecraft surfaces due to fluxes of high energy electrons onto and through them. Thus, satellite surfaces can charge thousands of volts with respect to each other whereas entire satellites can charge tens of thousands of volts negative of their surrounding space plasma. The ensuing electric fields can cause local discharges (arcs), endangering the normal operation of the satellite. Remote detection of spacecraft arcing is important for the satellite operators in order to properly respond to anomalies caused by spacecraft charging due to the space weather conditions. However, analysis of satellite data is laborious due to the amount of data generated. In this work, we explored the application of machine learning for analysis of GEO satellite arcing behavior using the radio frequency observations by the Arecibo 305 m telescope.\nView article\n","permalink":"http://localhost:1313/posts/application-of-machine-learning-to-investigation-of-arcing-on-geosynchronous-satellites/","tags":["Paper","Publications","2022"],"title":"Tracking whole-brain connectivity dynamics in the resting state"},{"categories":["Publications"],"contents":"Authors : Md Mahfuzur Rahman, Noah Lewis, Sergey Plis\nPublication date : 2014/3/1\nConference : ICLR 2022 Workshop on PAIR {\\textasciicircum\nDescription\nInterpretability methods for deep neural networks mainly focus on modifying the rules of automatic differentiation or perturbing the input and observing the score drop to determine the most relevant features. Among them, gradient-based attribution methods, such as saliency maps, are arguably the most popular. Still, the produced saliency maps may often lack intelligibility. We address this problem based on recent discoveries in geometric properties of deep neural networks\u0026rsquo; loss landscape that reveal the existence of a multiplicity of local minima in the vicinity of a trained model\u0026rsquo;s loss surface. We introduce two methods that leverage the geometry of the loss landscape to improve interpretability: 1)\u0026quot; Geometrically Guided Integrated Gradients\u0026quot;, applying gradient ascent to each interpolation point of the linear path as a guide. 2)\u0026quot; Geometric Ensemble Gradients\u0026quot;, generating ensemble saliency maps by sampling proximal iso-loss models. Compared to vanilla and integrated gradients, these methods significantly improve saliency maps in quantitative and visual terms. We verify our findings on MNIST and Imagenet datasets across convolutional, ResNet, and Inception V3 architectures.\nView article\n","permalink":"http://localhost:1313/posts/geometrically-guided-saliency-maps/","tags":["Paper","Publications"],"title":"Geometrically Guided Saliency Maps"},{"categories":["Publications"],"contents":"Authors : Shile Qi, Rogers F Silva, Daoqiang Zhang, Sergey M Plis, Robyn Miller, Victor M Vergara, Rongtao Jiang, Dongmei Zhi, Jing Sui, Vince D Calhoun\nPublication date : 2022/3/1\nJournal : Human brain mapping\nVolume : 43\nIssue : 4\nPages : 1280-1294\nPublisher : John Wiley \u0026amp; Sons, Inc.\nDescription\nAdvances in imaging acquisition techniques allow multiple imaging modalities to be collected from the same subject. Each individual modality offers limited yet unique views of the functional, structural, or dynamic temporal features of the brain. Multimodal fusion provides effective ways to leverage these complementary perspectives from multiple modalities. However, the majority of current multimodal fusion approaches involving functional magnetic resonance imaging (fMRI) are limited to 3D feature summaries that do not incorporate its rich temporal information. Thus, we propose a novel three‐way parallel group independent component analysis (pGICA) fusion method that incorporates the first‐level 4D fMRI data (temporal information included) by parallelizing group ICA into parallel ICA via a unified optimization framework. A new variability matrix was defined to capture subject‐wise functional variability and then …\nView article\n","permalink":"http://localhost:1313/posts/three-way-parallel-group-independent-component-analysis-fusion-of-spatial-and-spatiotemporal-magnetic-resonance-imaging-data/","tags":["Paper","Publications"],"title":"Three‐way parallel group independent component analysis: Fusion of spatial and spatiotemporal magnetic resonance imaging data"},{"categories":["Publications"],"contents":"Authors : Weizheng Yan, Gang Qu, Wenxing Hu, Anees Abrol, Biao Cai, Chen Qiao, Sergey M Plis, Yu-Ping Wang, Jing Sui, Vince D Calhoun\nPublication date : 2022/2/24\nJournal : IEEE Signal Processing Magazine\nVolume : 39\nIssue : 2\nPages : 87-98\nPublisher : IEEE\nDescription\nDeep learning (DL) has been extremely successful when applied to the analysis of natural images. By contrast, analyzing neuroimaging data presents some unique challenges, including higher dimensionality, smaller sample sizes, multiple heterogeneous modalities, and a limited ground truth. In this article, we discuss DL methods in the context of four diverse and important categories in the neuroimaging field: classification/prediction, dynamic activity/connectivity, multimodal fusion, and interpretation/visualization. We highlight recent progress in each of these categories, discuss the benefits of combining data characteristics and model architectures, and derive guidelines for the use of DL in neuroimaging data. For each category, we also assess promising applications and major challenges to overcome. Finally, we discuss future directions of neuroimaging DL for clinical applications, a topic of great interest …\nView article\n","permalink":"http://localhost:1313/posts/deep-learning-in-neuroimaging-promises-and-challenges/","tags":["Paper","Publications"],"title":"Deep learning in neuroimaging: Promises and challenges"},{"categories":["Classes"],"contents":"Introduction to Deep Learning Welcome to the introduction to deep learning course! ​ This course is designed to provide you with a solid foundation in the fundamentals of deep learning. Throughout this course, you will learn about the basic building blocks of deep learning, including basics of machine learning, convolutional neural networks, and natural language processing. You will also gain an understanding of how deep learning algorithms are used to solve a variety of real-world problems, such as image classification, natural language processing and a few advance approaches such as GANs. ​\nBy the end of the course, you will have a solid understanding of the core concepts and techniques used in deep learning, as well as hands-on experience building and training your own deep learning models using popular frameworks such as PyTorch and Catalyst ​\nDr. Sergey Plis is the instructor for this course, bringing his expertise of an active researcher in the fields of neuroscience and computer science. He has extensive experience applying machine learning algorithms to the analysis of brain imaging data. He is also an experienced educator, having taught numerous courses in data science, machine learning, and deep learning at the graduate and undergraduate levels. ​\nThe hands-on part of the course has been developed by Mrinal Mathur, a seasoned machine learning engineer with experience building and deploying machine learning models for a variety of industries. Mrinal has a deep understanding of the underlying mathematical and statistical concepts that power deep learning algorithms, and he has a passion for teaching others about the exciting possibilities of this field. ​\nTogether, we have designed a comprehensive and engaging course that will provide you with the knowledge and skills you need to succeed in the exciting field of deep learning. ​\nIntroduction to Deep Learning 1. Introduction Lecture Slides Introduction to Collab Pandas (optional) Lecture Slides Numpy Machine Learning 2. Foundations of Machine Learning Calculus and Optimization\nLecture Slides Linear Regression/Classification\nLecture Slides Perceptron\nLecture Slides 3. Automatic Differentitation Lecture Slides Colab Notebooks Automatic Differentitation programming 4. Practice for Automatic Differentiation Lecture Slides 5. Pytorch Colab Notebooks\nIntroduction to Pytorch and Catalyst 6. Model Comparision Lecture slides Colab Notebook Model Comparision Computer Vision 7. Computer Vision and Image Processing Lecture Slides Colab Notebook\nIntroduction to Computer Vision 8. Convolution Neural Network Lecture Slides Colab Notebook:\nIntroduction to CNNs 9. Image Classification Lecture Slides Colab Notebook\nClassification in Computer vision 10. Skip Connections and ResNets Colab Notebook\nIntro to Skip Connections and ResNets 11. Segmentation Lecture Slides Colab Notebook\nImage Segmentation 12. Auto-Encoders Lecture Slides Colab Notebooks:\nAuto-Encoders Variational Autoencoders 13. Generative Adversarial Nets Lecture Slides Colab Notebook:\nGenerative Adversarial Nets 14. Regularization Lecture Slides Natural Language Processing 15. Introduction to NLP Lecture Slides Colab Notebooks:\nIntroduction to NLP 16. Recurrent Neural Networks Colab Notebooks:\nRNNs 17. LSTM and GRU Lecture Slides Colab Notebook:\nLSTM and GRU in pytorch 18. Seq2Seq2 Lecture Slides Colab Notebooks:\nseq2seq models 19. Attention is all you need! Lecture Slides Colab Notebooks:\nAttention Mechanisms 20. Transformers Lecture Slides Colab Notebooks:\nTransformers Advance Topics (To be added) [Graph Neural Networks] [Reinforcement Learning] [Meta Learning] [Adversarial Learning] [Transfer Learning] [Self Supervised Learning] [Few Shot Learning] [Active Learning] [Multi Task Learning] [Multi Modal Learning] [Domain Adaptation] [Continual Learning] [Causal Learning] ","permalink":"http://localhost:1313/posts/introduction_to_dl/","tags":null,"title":"Introduction to Deep Learning"},{"categories":["Publications"],"contents":"Authors : Usman Mahmood, Zening Fu, Vince Calhoun, Sergey Plis\nPublication date : 2022/2/4\nJournal : arXiv preprint arXiv:2202.02393\nDescription\nRecently, methods that represent data as a graph, such as graph neural networks (GNNs) have been successfully used to learn data representations and structures to solve classification and link prediction problems. The applications of such methods are vast and diverse, but most of the current work relies on the assumption of a static graph. This assumption does not hold for many highly dynamic systems, where the underlying connectivity structure is non-stationary and is mostly unobserved. Using a static model in these situations may result in sub-optimal performance. In contrast, modeling changes in graph structure with time can provide information about the system whose applications go beyond classification. Most work of this type does not learn effective connectivity and focuses on cross-correlation between nodes to generate undirected graphs. An undirected graph is unable to capture direction of an interaction which is vital in many fields, including neuroscience. To bridge this gap, we developed dynamic effective connectivity estimation via neural network training (DECENNT), a novel model to learn an interpretable directed and dynamic graph induced by the downstream classification/prediction task. DECENNT outperforms state-of-the-art (SOTA) methods on five different tasks and infers interpretable task-specific dynamic graphs. The dynamic graphs inferred from functional neuroimaging data align well with the existing literature and provide additional information. Additionally, the temporal attention module of DECENNT identifies time-intervals crucial for predictive downstream task from multivariate time series data.\nView article\n","permalink":"http://localhost:1313/posts/deep-dynamic-effective-connectivity-estimation-from-multivariate-time-series/","tags":["Paper","Publications","2022"],"title":"Deep Dynamic Effective Connectivity Estimation from Multivariate Time Series"},{"categories":["Publications"],"contents":"Authors : Harshvardhan Gazula, Kelly Rootes-Murdy, Bharath Holla, Sunitha Basodi, Zuo Zhang, Eric Verner, Ross Kelly, Pratima Murthy, Amit Chakrabarti, Debasish Basu, Subodh Bhagyalakshmi Nanjayya, Rajkumar Lenin Singh, Roshan Lourembam Singh, Kartik Kalyanram, Kamakshi Kartik, Kumaran Kalyanaraman, Krishnaveni Ghattu, Rebecca Kuriyan, Sunita Simon Kurpad, Gareth J Barker, Rose Dawn Bharath, Sylvane Desrivieres, Meera Purushottam, Dimitri Papadopoulos Orfanos, Eesha Sharma, Matthew Hickman, Mireille Toledano, Nilakshi Vaidya, Tobias Banaschewski, Arun LW Bokde, Herta Flor, Antoine Grigis, Hugh Garavan, Penny Gowland, Andreas Heinz, Rüdiger Brühl, Jean-Luc Martinot, Marie-Laure Paillère Martinot, Eric Artiges, Frauke Nees, Tomáš Paus, Luise Poustka, Juliane H Fröhner, Lauren Robinson, Michael N Smolka, Henrik Walter, Jeanne Winterer, Robert Whelan, Jessica A Turner, Anand D Sarwate, Sergey M Plis, Vivek Benegal, Gunter Schumann, Vince D Calhoun, IMAGEN Consortium\nPublication date : 2022/1/1\nJournal : bioRxiv\nPublisher : Cold Spring Harbor Laboratory\nDescription\nWith the growth of decentralized/federated analysis approaches in neuroimaging, the opportunities to study brain disorders using data from multiple sites has grown multi-fold. One such initiative is the Neuromark, a fully automated spatially constrained independent component analysis (ICA) that is used to link brain network abnormalities among different datasets, studies, and disorders while leveraging subject-specific networks. In this study, we implement the neuromark pipeline in COINSTAC, an open-source neuroimaging framework for collaborative/decentralized analysis. Decentralized analysis of nearly 2000 resting-state functional magnetic resonance imaging datasets collected at different sites across two cohorts and co-located in different countries was performed to study the resting brain functional network connectivity changes in adolescents who smoke and consume alcohol. Results showed hypoconnectivity across the majority of networks including sensory, default mode, and subcortical domains, more for alcohol than smoking, and decreased low frequency power. These findings suggest that global reduced synchronization is associated with both tobacco and alcohol use. This work demonstrates the utility and incentives associated with large-scale decentralized collaborations spanning multiple sites.\nView article\n","permalink":"http://localhost:1313/posts/federated-analysis-in-coinstac-reveals-functional-network-connectivity-and-spectral-links-to-smoking-and-alcohol-consumption-in-nearly-2000-adolescent-brains/","tags":["Paper","Publications"],"title":"Federated analysis in COINSTAC reveals functional network connectivity and spectral links to smoking and alcohol consumption in nearly 2,000 adolescent brains"},{"categories":["Publications"],"contents":"Authors : Haleh Falakshahi, Hooman Rokham, Zening Fu, Armin Iraji, Daniel H Mathalon, Judith M Ford, Bryon A Mueller, Adrian Preda, Theo GM van Erp, Jessica A Turner, Sergey Plis, Vince D Calhoun\nPublication date : 2022/1\nJournal : Network Neuroscience\nPages : 1-45\nDescription\nGraph-theoretical methods have been widely used to study human brain networks in psychiatric disorders. However, the focus has primarily been on global graphic metrics with little attention to the information contained in paths connecting brain regions. Details of disruption of these paths may be highly informative for understanding disease mechanisms. To detect the absence or addition of multistep paths in the patient group, we provide an algorithm estimating edges that contribute to these paths with reference to the control group. We next examine where pairs of nodes were connected through paths in both groups by using a covariance decomposition method. We apply our method to study resting-state fMRI data in schizophrenia versus controls. Results show several disconnectors in schizophrenia within and between functional domains, particularly within the default mode and cognitive control networks …\nView article\n","permalink":"http://localhost:1313/posts/path-analysis-a-method-to-estimate-altered-pathways-in-time-varying-graphs-of-neuroimaging-data/","tags":["Paper","Publications"],"title":"Path analysis: A method to estimate altered pathways in time-varying graphs of neuroimaging data"},{"categories":["Publications"],"contents":"Authors : Samin Yeasar Arnob, Riyasat Ohib, Sergey Plis, Doina Precup\nPublication date : 2021/12/31\nJournal : arXiv preprint arXiv:2112.15579\nDescription\nDeep Reinforcement Learning (RL) is a powerful framework for solving complex real-world problems. Large neural networks employed in the framework are traditionally associated with better generalization capabilities, but their increased size entails the drawbacks of extensive training duration, substantial hardware resources, and longer inference times. One way to tackle this problem is to prune neural networks leaving only the necessary parameters. State-of-the-art concurrent pruning techniques for imposing sparsity perform demonstrably well in applications where data distributions are fixed. However, they have not yet been substantially explored in the context of RL. We close the gap between RL and single-shot pruning techniques and present a general pruning approach to the Offline RL. We leverage a fixed dataset to prune neural networks before the start of RL training. We then run experiments varying the network sparsity level and evaluating the validity of pruning at initialization techniques in continuous control tasks. Our results show that with 95% of the network weights pruned, Offline-RL algorithms can still retain performance in the majority of our experiments. To the best of our knowledge, no prior work utilizing pruning in RL retained performance at such high levels of sparsity. Moreover, pruning at initialization techniques can be easily integrated into any existing Offline-RL algorithms without changing the learning objective.\nView article\n","permalink":"http://localhost:1313/posts/single-shot-pruning-for-offline-reinforcement-learning/","tags":["Paper","Publications"],"title":"Single-shot pruning for offline reinforcement learning"},{"categories":["Publications"],"contents":"Authors : Elena A Allen, Eswar Damaraju, Sergey M Plis, Erik B Erhardt, Tom Eichele, Vince D Calhoun\nPublication date : 2021/11/22\nSource : Neuroinformatics\nPages : 1-14\nPublisher : Springer US\nDescription\nThe field of neuroimaging has embraced sharing data to collaboratively advance our understanding of the brain. However, data sharing, especially across sites with large amounts of protected health information (PHI), can be cumbersome and time intensive. Recently, there has been a greater push towards collaborative frameworks that enable large-scale federated analysis of neuroimaging data without the data having to leave its original location. However, there still remains a need for a standardized federated approach that not only allows for data sharing adhering to the FAIR (Findability, Accessibility, Interoperability, Reusability) data principles, but also streamlines analyses and communication while maintaining subject privacy. In this paper, we review a non-exhaustive list of neuroimaging analytic tools and frameworks currently in use. We then provide an update on our federated neuroimaging analysis …\nView article\n","permalink":"http://localhost:1313/posts/federated-analysis-of-neuroimaging-data-a-review-of-the-field/","tags":["Paper","Publications"],"title":"Federated analysis of neuroimaging data: A review of the field"},{"categories":["Publications"],"contents":"Title: 205. Deep Learning Approaches to Unimodal and Multimodal Analysis of Brain Imaging Data With Applications to Mental Illness\nAuthors: Vince Calhoun, Sergey Plis\nYear: 2018\nJournal: Biological Psychiatry\nVolume: 83\nNumber: 9\nPages: S82-S83\nPublisher: Elsevier\nDescription:\nBackgroundDeep learning analytic approaches have made inroads into the brain imaging field, but they are still relatively new and the specific applications which can benefit from such models are not yet fully developed. In this talk I will present some work in which we have developed deep learning models with application to structural and functional brain imaging data in mental illness including schizophrenia, bipolar disorder, and Huntington’s disease.MethodsWe apply and discuss several recent deep learning models which were developed for application to brain imaging data. The first model is focused on structural MRI data, the second on fMRI data, and the third on functional and structural data integration. We then demonstrate performance of these models on several multi-site studies of schizophrenia, bipolar disorder, and Huntington’s disease.ResultsResults provide strong evidence for the potential of deep …\nView article\n","permalink":"http://localhost:1313/posts/205.-deep-learning-approaches-to-unimodal-and-multimodal-analysis-of-brain-imaging-data-with-applications-to-mental-illness/","tags":["Paper","Publications"],"title":"205. Deep Learning Approaches to Unimodal and Multimodal Analysis of Brain Imaging Data With Applications to Mental Illness"},{"categories":["Publications"],"contents":"Title: A classification-based approach to estimate the number of resting functional magnetic resonance imaging dynamic functional connectivity states\nAuthors: Debbrata K Saha, Eswar Damaraju, Barnaly Rashid, Anees Abrol, Sergey M Plis, Vince D Calhoun\nYear: 2021\nJournal: Brain connectivity\nVolume: 11\nNumber: 2\nPages: 132-145\nPublisher: Mary Ann Liebert, Inc., publishers\nDescription:\nAim: To determine the optimal number of connectivity states in dynamic functional connectivity analysis.Introduction: Recent work has focused on the study of dynamic (vs. static) brain connectivity in resting functional magnetic resonance imaging data. In this work, we focus on temporal correlation between time courses extracted from coherent networks called functional network connectivity (FNC). Dynamic FNC is most commonly estimated using a sliding window-based approach to capture short periods of FNC change. These data are then clustered to estimate transient connectivity patterns or states. Determining the number of states is a challenging problem. The elbow criterion is one of the widely used approaches to determine the connectivity states.Materials and Methods: In our work, we present an alternative approach that evaluates classification (e.g., healthy controls [HCs] vs. patients) as a measure to …\nView article\n","permalink":"http://localhost:1313/posts/a-classification-based-approach-to-estimate-the-number-of-resting-functional-magnetic-resonance-imaging-dynamic-functional-connectivity-states/","tags":["Paper","Publications"],"title":"A classification-based approach to estimate the number of resting functional magnetic resonance imaging dynamic functional connectivity states"},{"categories":["Publications"],"contents":"Title: A constraint optimization approach to causal discovery from subsampled time series data\nAuthors: Antti Hyttinen, Sergey Plis, Matti Järvisalo, Frederick Eberhardt, David Danks\nYear: 2017\nJournal: International Journal of Approximate Reasoning\nVolume: 90\nPages: 208-225\nPublisher: Elsevier\nDescription:\nWe consider causal structure estimation from time series data in which measurements are obtained at a coarser timescale than the causal timescale of the underlying system. Previous work has shown that such subsampling can lead to significant errors about the system's causal structure if not properly taken into account. In this paper, we first consider the search for system timescale causal structures that correspond to a given measurement timescale structure. We provide a constraint satisfaction procedure whose computational performance is several orders of magnitude better than previous approaches. We then consider finite-sample data as input, and propose the first constraint optimization approach for recovering system timescale causal structure. This algorithm optimally recovers from possible conflicts due to statistical errors. We then apply the method to real-world data, investigate the robustness and …\nView article\n","permalink":"http://localhost:1313/posts/a-constraint-optimization-approach-to-causal-discovery-from-subsampled-time-series-data/","tags":["Paper","Publications"],"title":"A constraint optimization approach to causal discovery from subsampled time series data"},{"categories":["Publications"],"contents":"Title: A Correlated Noise-Assisted Decentralized Differentially Private Estimation Protocol, and its Application to fMRI Source Separation\nAuthors: Hafiz Imtiaz, Jafar Mohammadi, Rogers Silva, Bradley Baker, Sergey M Plis, Anand D Sarwate, Vince D Calhoun\nYear: 2021\nJournal: IEEE Transactions on Signal Processing\nVolume: 69\nPages: 6355-6370\nPublisher: IEEE\nDescription:\nBlind source separation algorithms such as independent component analysis (ICA) are widely used in the analysis of neuroimaging data. To leverage larger sample sizes, different data holders/sites may wish to collaboratively learn feature representations. However, such datasets are often privacy-sensitive, precluding centralized analyses that pool the data at one site. In this work, we propose a differentially private algorithm for performing ICA in a decentralized data setting. Due to the high dimension and small sample size, conventional approaches to decentralized differentially private algorithms suffer in terms of utility. When centralizing the data is not possible, we investigate the benefit of enabling limited collaboration in the form of generating jointly distributed random noise. We show that such (anti) correlated noise improves the privacy-utility trade-off, and can reach the same level of utility as the corresponding …\nView article\n","permalink":"http://localhost:1313/posts/a-correlated-noise-assisted-decentralized-differentially-private-estimation-protocol-and-its-application-to-fmri-source-separation/","tags":["Paper","Publications"],"title":"A Correlated Noise-Assisted Decentralized Differentially Private Estimation Protocol, and its Application to fMRI Source Separation"},{"categories":["Publications"],"contents":"Title: A DEEP LEARNING APPROACH TO ESTIMATING INITIAL CONDITIONS OF BRAIN NETWORK MODELS IN REFERENCE TO MEASURED FMRI DATA\nAuthors: Amrit Kashyap, Sergey Plis, Michael Schirner, Petra Ritter, Shella Keilholz\nYear: 2021\nJournal: bioRxiv\nPublisher: Cold Spring Harbor Laboratory\nDescription:\nBrain Network Models (BNMs) are a family of dynamical systems that simulate whole brain activity using neural mass models to represent local activity in different brain regions that influence each other via a global structural network. Research has been interested in using these network models to explain measured whole brain activity measured via resting state functional magnetic resonance imaging (rs-fMRI). Properties computed over longer periods of simulated and measured data such as average functional connectivity (FC), have shown to be comparable with similar properties estimated from measured rs-fMRI data. While this shows that these network models have similar properties over the dynamical landscape, it is unclear how well simulated trajectories compare with empirical trajectories on a timepoint-by-timepoint basis. Previous studies have shown that BNMs are able to produce relevant features at shorter timescales, but analysis of short-term trajectories or transient dynamics as defined by synchronized predictions from BNM made at the same timescale as the collected data has not yet been conducted. Relevant neural processes exist in the time frame of measurements and are often used in task fMRI studies to understand neural responses to behavioral cues. Therefore, it is important to investigate how much of these dynamics are captured by our current brain simulations. To test the nature of BNMs short term trajectories against observed data, we utilize a deep learning technique known as Neural ODE that based on an observed sequence of fMRI measurements, estimates the initial conditions such that the BNM’s …\nView article\n","permalink":"http://localhost:1313/posts/a-deep-learning-approach-to-estimating-initial-conditions-of-brain-network-models-in-reference-to-measured-fmri-data/","tags":["Paper","Publications"],"title":"A DEEP LEARNING APPROACH TO ESTIMATING INITIAL CONDITIONS OF BRAIN NETWORK MODELS IN REFERENCE TO MEASURED FMRI DATA"},{"categories":["Publications"],"contents":"Title: A deep learning model for data-driven discovery of functional connectivity\nAuthors: Usman Mahmood, Zening Fu, Vince D Calhoun, Sergey Plis\nYear: 2021\nJournal: Algorithms\nVolume: 14\nNumber: 3\nPages: 75\nPublisher: MDPI\nDescription:\nFunctional connectivity (FC) studies have demonstrated the overarching value of studying the brain and its disorders through the undirected weighted graph of functional magnetic resonance imaging (fMRI) correlation matrix. However, most of the work with the FC depends on the way the connectivity is computed, and it further depends on the manual post-hoc analysis of the FC matrices. In this work, we propose a deep learning architecture BrainGNN that learns the connectivity structure as part of learning to classify subjects. It simultaneously applies a graphical neural network to this learned graph and learns to select a sparse subset of brain regions important to the prediction task. We demonstrate that the model’s state-of-the-art classification performance on a schizophrenia fMRI dataset and demonstrate how introspection leads to disorder relevant findings. The graphs that are learned by the model exhibit strong class discrimination and the sparse subset of relevant regions are consistent with the schizophrenia literature.\nView article\n","permalink":"http://localhost:1313/posts/a-deep-learning-model-for-data-driven-discovery-of-functional-connectivity/","tags":["Paper","Publications"],"title":"A deep learning model for data-driven discovery of functional connectivity"},{"categories":["Publications"],"contents":"Title: A Method for Analyzing Abnormal Integration Between the Brain Regions in Schizophrenia\nAuthors: Haleh Falakshahi, Hooman Rokham, Victor Vergara, Sergey Plis, Vince Calhoun\nYear: 2020\nJournal: Biological Psychiatry\nVolume: 87\nNumber: 9\nPages: S136\nPublisher: Elsevier\nDescription:\nBackgroundSchizophrenia (SZ) can be distinguished by functional disconnectivity or abnormal integration between distant brain regions. A complete research program needs to integrate both aspect of disconnectivity and integration that may happen among the brain regions. By using a Gaussian graphical model approach, we identified ‘missing’connections between multimodal data and the disconnectors associated with them in SZ. In the present study we explored the added connections in the SZ data.MethodsWe analyzed data from the fBIRN study that included fMRI, dMRI, and sMRI including147 healthy subjects and 147 SZ patients. We estimated the fractional amplitude of low frequency fluctuations, fractional anisotropy, and gray matter maps as input features. We applied three-way pICA to these features. We used a joint estimator to extract graphs for healthy and SZ. We then used the concept of connected …\nView article\n","permalink":"http://localhost:1313/posts/a-method-for-analyzing-abnormal-integration-between-the-brain-regions-in-schizophrenia/","tags":["Paper","Publications"],"title":"A Method for Analyzing Abnormal Integration Between the Brain Regions in Schizophrenia"},{"categories":["Publications"],"contents":"Title: A tool for interactive data visualization: application to over 10,000 brain imaging and phantom MRI data sets\nAuthors: Sandeep R Panta, Runtang Wang, Jill Fries, Ravi Kalyanam, Nicole Speer, Marie Banich, Kent Kiehl, Margaret King, Michael Milham, Tor D Wager, Jessica A Turner, Sergey M Plis, Vince D Calhoun\nYear: 2016\nJournal: Frontiers in neuroinformatics\nVolume: 10\nPages: 9\nPublisher: Frontiers Media SA\nDescription:\nIn this paper we propose a web-based approach for quick visualization of big data from brain magnetic resonance imaging (MRI) scans using a combination of an automated image capture and processing system, nonlinear embedding, and interactive data visualization tools. We draw upon thousands of MRI scans captured via the COllaborative Imaging and Neuroinformatics Suite (COINS). We then interface the output of several analysis pipelines based on structural and functional data to a t-distributed stochastic neighbor embedding (t-SNE) algorithm which reduces the number of dimensions for each scan in the input data set to two dimensions while preserving the local structure of data sets. Finally, we interactively display the output of this approach via a web-page, based on data driven documents (D3) JavaScript library. Two distinct approaches were used to visualize the data. In the first approach, we computed multiple quality control (QC) values from pre-processed data, which were used as inputs to the t-SNE algorithm. This approach helps in assessing the quality of each data set relative to others. In the second case, computed variables of interest (e.g. brain volume or voxel values from segmented gray matter images) were used as inputs to the t-SNE algorithm. This approach helps in identifying interesting patterns in the data sets. We demonstrate these approaches using multiple examples including 1) quality control measures calculated from phantom data over time, 2) quality control data from human functional MRI data across various studies, scanners, sites, 3) volumetric and density measures from human structural MRI data across …\nView article\n","permalink":"http://localhost:1313/posts/a-tool-for-interactive-data-visualization-application-to-over-10000-brain-imaging-and-phantom-mri-data-sets/","tags":["Paper","Publications"],"title":"A tool for interactive data visualization: application to over 10,000 brain imaging and phantom MRI data sets"},{"categories":["Publications"],"contents":"Title: Addressing inaccurate nosology in mental health: A multilabel data cleansing approach for detecting label noise from structural magnetic resonance imaging data in mood and psychosis disorders\nAuthors: Hooman Rokham, Godfrey Pearlson, Anees Abrol, Haleh Falakshahi, Sergey Plis, Vince D Calhoun\nYear: 2020\nJournal: Biological Psychiatry: Cognitive Neuroscience and Neuroimaging\nVolume: 5\nNumber: 8\nPages: 819-832\nPublisher: Elsevier\nDescription:\nMental health diagnostic approaches are seeking to identify biological markers to work alongside advanced machine learning approaches. It is difficult to identify a biological marker of disease when the traditional diagnostic labels themselves are not necessarily valid.We worked with T1 structural magnetic resonance imaging data collected from 1493 individuals comprising healthy control subjects, patients with psychosis, and their unaffected first-degree relatives. Specifically, the dataset included 176 bipolar disorder probands, 134 schizoaffective disorder probands, 240 schizophrenia probands, 362 control subjects, and 581 patient relatives. We assumed that there might be noise in the diagnostic labeling process. We detected label noise by classifying the data multiple times using a support vector machine classifier, and then we flagged those individuals in which all classifiers unanimously …\nView article\n","permalink":"http://localhost:1313/posts/addressing-inaccurate-nosology-in-mental-health-a-multilabel-data-cleansing-approach-for-detecting-label-noise-from-structural-magnetic-resonance-imaging-data-in-mood-and-psychosis-disorders/","tags":["Paper","Publications"],"title":"Addressing inaccurate nosology in mental health: A multilabel data cleansing approach for detecting label noise from structural magnetic resonance imaging data in mood and psychosis disorders"},{"categories":["Publications"],"contents":"Title: Algorithm-Agnostic Explainability for Unsupervised Clustering\nAuthors: Charles A Ellis, Mohammad SE Sendi, Eloy Geenjaar, Sergey M Plis, Robyn L Miller, Vince D Calhoun\nYear: 2021\nJournal: arXiv preprint arXiv:2105.08053\nDescription:\nSupervised machine learning explainability has developed rapidly in recent years. However, clustering explainability has lagged behind. Here, we demonstrate the first adaptation of model-agnostic explainability methods to explain unsupervised clustering. We present two novel \u0026quot;algorithm-agnostic\u0026quot; explainability methods - global permutation percent change (G2PC) and local perturbation percent change (L2PC) - that identify feature importance globally to a clustering algorithm and locally to the clustering of individual samples. The methods are (1) easy to implement and (2) broadly applicable across clustering algorithms, which could make them highly impactful. We demonstrate the utility of the methods for explaining five popular clustering methods on low-dimensional synthetic datasets and on high-dimensional functional network connectivity data extracted from a resting-state functional magnetic resonance imaging dataset of 151 individuals with schizophrenia and 160 controls. Our results are consistent with existing literature while also shedding new light on how changes in brain connectivity may lead to schizophrenia symptoms. We further compare the explanations from our methods to an interpretable classifier and find them to be highly similar. Our proposed methods robustly explain multiple clustering algorithms and could facilitate new insights into many applications. We hope this study will greatly accelerate the development of the field of clustering explainability.\nView article\n","permalink":"http://localhost:1313/posts/algorithm-agnostic-explainability-for-unsupervised-clustering/","tags":["Paper","Publications"],"title":"Algorithm-Agnostic Explainability for Unsupervised Clustering"},{"categories":["Publications"],"contents":"Title: Almost instant brain atlas segmentation for large-scale studies\nAuthors: Alex Fedorov, Eswar Damaraju, Vince Calhoun, Sergey Plis\nYear: 2017\nJournal: arXiv preprint arXiv:1711.00457\nDescription:\nLarge scale studies of group differences in healthy controls and patients and screenings for early stage disease prevention programs require processing and analysis of extensive multisubject datasets. Complexity of the task increases even further when segmenting structural MRI of the brain into an atlas with more than 50 regions. Current automatic approaches are time-consuming and hardly scalable; they often involve many error prone intermediate steps and don't utilize other available modalities. To alleviate these problems, we propose a feedforward fully convolutional neural network trained on the output produced by the state of the art models. Incredible speed due to available powerful GPUs neural network makes this analysis much easier and faster (from hours to a minute). The proposed model is more than two orders of magnitudes faster than the state of the art and yet as accurate. We have evaluated the network's performance by comparing it with the state of the art in the task of differentiating region volumes of healthy controls and patients with schizophrenia on a dataset with 311 subjects. This comparison provides a strong evidence that speed did not harm the accuracy. The overall quality may also be increased by utilizing multi-modal datasets (not an easy task for other models) by simple adding more modalities as an input. Our model will be useful in large-scale studies as well as in clinical care solutions, where it can significantly reduce delay between the patient screening and the result.\nView article\n","permalink":"http://localhost:1313/posts/almost-instant-brain-atlas-segmentation-for-large-scale-studies/","tags":["Paper","Publications"],"title":"Almost instant brain atlas segmentation for large-scale studies"},{"categories":["Publications"],"contents":"Title: Amalgamating evidence of dynamics\nAuthors: David Danks, Sergey Plis\nYear: 2019\nJournal: Synthese\nVolume: 196\nNumber: 8\nPages: 3213-3230\nPublisher: Springer Netherlands\nDescription:\nMany approaches to evidence amalgamation focus on relatively static information or evidence: the data to be amalgamated involve different variables, contexts, or experiments, but not measurements over extended periods of time. However, much of scientific inquiry focuses on dynamical systems; the system’s behavior over time is critical. Moreover, novel problems of evidence amalgamation arise in these contexts. First, data can be collected at different measurement timescales, where potentially none of them correspond to the underlying system’s causal timescale. Second, missing variables have a significantly different impact on time series measurements than they do in the traditional static setting; in particular, they make causal and structural inference much more difficult. In this paper, we argue that amalgamation should proceed by integrating causal knowledge, rather than at the level of “raw” evidence …\nView article\n","permalink":"http://localhost:1313/posts/amalgamating-evidence-of-dynamics/","tags":["Paper","Publications"],"title":"Amalgamating evidence of dynamics"},{"categories":["Publications"],"contents":"Title: B58 BIG AND BIGGER (DATA): OMICS AND BIOMARKERS OF COPD AND OTHER CHRONIC LUNG DISEASES: Support Vector Machine Identifies A Set Of Metabolites In Plasma That Predict Rapid Fev1 Decline In Humans And Mice\nAuthors: H Petersen, J Sui, S Plis, Y Tesfaigzi\nYear: 2016\nJournal: American Journal of Respiratory and Critical Care Medicine\nVolume: 193\nPages: 1\nPublisher: American Thoracic Society\nDescription:\nBackground: Although extrinsic factors such as age, gender, drug use, or diet can affect metabolic profiles, metabolic alterations in the blood are associated with disease progression. The goal of this study was to identify metabolic biomarkers that are associated with lung function decline in humans. Because we found that loss of Bik, a Bcl-2 family protein, causes the development of enhanced emphysema as mice age, we investigated whether a common set of metabolites could predict both rapid FEV1 decline in humans and in bik-/-mice.Methods: Plasma samples were from 60 each Hispanic (Hisp) and non-Hispanic White (NHW) participants of the Lovelace Smokers Cohort (LSC). Thirty one NHW rapid decliners (RDs)(mean decline rate 137 ml/year) were matched to 29 NHW non-decliners (NDs)(mean change rate+ 15 ml/year). Thirty Hisp RDs (mean decline rate 78 ml/year) were matched to 30 Hisp NDs (mean …\nView article\n","permalink":"http://localhost:1313/posts/b58-big-and-bigger-data-omics-and-biomarkers-of-copd-and-other-chronic-lung-diseases-support-vector-machine-identifies-a-set-of-metabolites-in-plasma-that-predict-rapid-fev1-decline-in-humans-and-mice/","tags":["Paper","Publications"],"title":"B58 BIG AND BIGGER (DATA): OMICS AND BIOMARKERS OF COPD AND OTHER CHRONIC LUNG DISEASES: Support Vector Machine Identifies A Set Of Metabolites In Plasma That Predict Rapid Fev1 Decline In Humans And Mice"},{"categories":["Publications"],"contents":"Title: Bayesian brain source imaging based on combined MEG EEG and fMRI using MCMC\nAuthors: Sung C Jun, John S George, Woohan Kim, Juliana Paré-Blagoev, Sergey Plis, Doug M Ranken, David M Schmidt\nYear: 2008\nJournal: NeuroImage\nVolume: 40\nNumber: 4\nPages: 1581-1594\nPublisher: Academic Press\nDescription:\nA number of brain imaging techniques have been developed in order to investigate brain function and to develop diagnostic tools for various brain disorders. Each modality has strengths as well as weaknesses compared to the others. Recent work has explored how multiple modalities can be integrated effectively so that they complement one another while maintaining their individual strengths. Bayesian inference employing Markov Chain Monte Carlo (MCMC) techniques provides a straightforward way to combine disparate forms of information while dealing with the uncertainty in each. In this paper we introduce methods of Bayesian inference as a way to integrate different forms of brain imaging data in a probabilistic framework. We formulate Bayesian integration of magnetoencephalography (MEG) data and functional magnetic resonance imaging (fMRI) data by incorporating fMRI data into a spatial prior. The …\nView article\n","permalink":"http://localhost:1313/posts/bayesian-brain-source-imaging-based-on-combined-meg-eeg-and-fmri-using-mcmc/","tags":["Paper","Publications"],"title":"Bayesian brain source imaging based on combined MEG EEG and fMRI using MCMC"},{"categories":["Publications"],"contents":"Title: Blind source separation for unimodal and multimodal brain networks: A unifying framework for subspace modeling\nAuthors: Rogers F Silva, Sergey M Plis, Jing Sui, Marios S Pattichis, Tülay Adalı, Vince D Calhoun\nYear: 2016\nJournal: IEEE journal of selected topics in signal processing\nVolume: 10\nNumber: 7\nPages: 1134-1149\nPublisher: IEEE\nDescription:\nIn the past decade, numerous advances in the study of the human brain were fostered by successful applications of blind source separation (BSS) methods to a wide range of imaging modalities. The main focus has been on extracting “networks” represented as the underlying latent sources. While the broad success in learning latent representations from multiple datasets has promoted the wide presence of BSS in modern neuroscience, it also introduced a wide variety of objective functions, underlying graphical structures, and parameter constraints for each method. Such diversity, combined with a host of datatype-specific know-how, can cause a sense of disorder and confusion, hampering a practitioner's judgment and impeding further development. We organize the diverse landscape of BSS models by exposing its key features and combining them to establish a novel unifying view of the area. In the process, we …\nView article\n","permalink":"http://localhost:1313/posts/blind-source-separation-for-unimodal-and-multimodal-brain-networks-a-unifying-framework-for-subspace-modeling/","tags":["Paper","Publications"],"title":"Blind source separation for unimodal and multimodal brain networks A unifying framework for subspace modeling"},{"categories":["Publications"],"contents":"Title: Brain dynamics via Cumulative Auto-Regressive Self-Attention\nAuthors: Usman Mahmood, Zening Fu, Vince Calhoun, Sergey Plis\nYear: 2021\nJournal: arXiv preprint arXiv:2111.01271\nDescription:\nMultivariate dynamical processes can often be intuitively described by a weighted connectivity graph between components representing each individual time-series. Even a simple representation of this graph as a Pearson correlation matrix may be informative and predictive as demonstrated in the brain imaging literature. However, there is a consensus expectation that powerful graph neural networks (GNNs) should perform better in similar settings. In this work, we present a model that is considerably shallow than deep GNNs, yet outperforms them in predictive accuracy in a brain imaging application. Our model learns the autoregressive structure of individual time series and estimates directed connectivity graphs between the learned representations via a self-attention mechanism in an end-to-end fashion. The supervised training of the model as a classifier between patients and controls results in a model that generates directed connectivity graphs and highlights the components of the time-series that are predictive for each subject. We demonstrate our results on a functional neuroimaging dataset classifying schizophrenia patients and controls.\nView article\n","permalink":"http://localhost:1313/posts/brain-dynamics-via-cumulative-auto-regressive-self-attention/","tags":["Paper","Publications"],"title":"Brain dynamics via Cumulative Auto-Regressive Self-Attention"},{"categories":["Publications"],"contents":"Title: COINSTAC: a privacy enabled model and prototype for leveraging and processing decentralized brain imaging data\nAuthors: Sergey M Plis, Anand D Sarwate, Dylan Wood, Christopher Dieringer, Drew Landis, Cory Reed, Sandeep R Panta, Jessica A Turner, Jody M Shoemaker, Kim W Carter, Paul Thompson, Kent Hutchison, Vince D Calhoun\nYear: 2016\nJournal: Frontiers in neuroscience\nVolume: 10\nPages: 365\nPublisher: Frontiers Media SA\nDescription:\nThe field of neuroimaging has embraced the need for sharing and collaboration. Data sharing mandates from public funding agencies and major journal publishers have spurred the development of data repositories and neuroinformatics consortia. However, efficient and effective data sharing still faces several hurdles. For example, open data sharing is on the rise but is not suitable for sensitive data that are not easily shared, such as genetics. Current approaches can be cumbersome (such as negotiating multiple data sharing agreements). There are also significant data transfer, organization and computational challenges. Centralized repositories only partially address the issues. We propose a dynamic, decentralized platform for large scale analyses called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The COINSTAC solution can include data missing from central repositories, allows pooling of both open and closed\u0026amp;#x27;\u0026amp;#x27; repositories by developing privacy-preserving versions of widely-used algorithms, and incorporates the tools within an easy-to-use platform enabling distributed computation. We present an initial prototype system which we demonstrate on two multi-site data sets, without aggregating the data. In addition, by iterating across sites, the COINSTAC model enables meta-analytic solutions to converge to pooled-data'' solutions (i.e. as if the entire data were in hand). More advanced approaches such as feature generation, matrix factorization models, and preprocessing can be incorporated into such a model. In sum, COINSTAC enables access to the many currently unavailable …\nView article\n","permalink":"http://localhost:1313/posts/coinstac-a-privacy-enabled-model-and-prototype-for-leveraging-and-processing-decentralized-brain-imaging-data/","tags":["Paper","Publications"],"title":"COINSTAC - a privacy enabled model and prototype for leveraging and processing decentralized brain imaging data"},{"categories":["Publications"],"contents":"Title: Coinstac: Collaborative informatics and neuroimaging suite toolkit for anonymous computation\nAuthors: Harshvardhan Gazula, Ross Kelly, Javier Romero, Eric Verner, Bradley T Baker, Rogers F Silva, Hafiz Imtiaz, Debbrata Kumar Saha, Rajikha Raja, Jessica A Turner, Anand D Sarwate, Sergey M Plis, Vince D Calhoun\nYear: 2020\nJournal: Journal of Open Source Software\nVolume: 5\nNumber: 54\nPages: 2166\nDescription:\nCentral to the field of neuroimaging is the development of techniques for making sense of complex brain data. However, rapid technological advancements are pushing the spatial and temporal resolution of imaging in different modalities to an unprecedented level, leading to large datasets which cannot be analyzed in the traditional desktop computing paradigm. This has led to a paradigm shift in scientific research with an increasing emphasis on collaborative data sharing. However, current approaches to data sharing, such as negotiating multiple data sharing agreements, can be cumbersome. In addition, there are also significant data transfer, organizational, and computational challenges, the result being that collaborative group research requires a great deal of coordination. Human and business factors can hamper research from happening at a constructive pace, maybe even forbidding group research to occur at all.\nView article\n","permalink":"http://localhost:1313/posts/coinstac-collaborative-informatics-and-neuroimaging-suite-toolkit-for-anonymous-computation/","tags":["Paper","Publications"],"title":"COINSTAC - Collaborative informatics and neuroimaging suite toolkit for anonymous computation"},{"categories":["Publications"],"contents":"Title: COINSTAC: Decentralizing the future of brain imaging analysis\nAuthors: Jing Ming, Eric Verner, Anand Sarwate, Ross Kelly, Cory Reed, Torran Kahleck, Rogers Silva, Sandeep Panta, Jessica Turner, Sergey Plis, Vince Calhoun\nYear: 2017\nJournal: F1000Research\nVolume: 6\nPublisher: Faculty of 1000 Ltd\nDescription:\nIn the era of Big Data, sharing neuroimaging data across multiple sites has become increasingly important. However, researchers who want to engage in centralized, large-scale data sharing and analysis must often contend with problems such as high database cost, long data transfer time, extensive manual effort, and privacy issues for sensitive data. To remove these barriers to enable easier data sharing and analysis, we introduced a new, decentralized, privacy-enabled infrastructure model for brain imaging data called COINSTAC in 2016. We have continued development of COINSTAC since this model was first introduced. One of the challenges with such a model is adapting the required algorithms to function within a decentralized framework. In this paper, we report on how we are solving this problem, along with our progress on several fronts, including additional decentralized algorithms implementation, user …\nView article\n","permalink":"http://localhost:1313/posts/coinstac-decentralizing-the-future-of-brain-imaging-analysis/","tags":["Paper","Publications"],"title":"COINSTAC - Decentralizing the future of brain imaging analysis"},{"categories":["Publications"],"contents":"Title: Concurrent cross-sectional and longitudinal analyses of multivariate white matter profiles and clinical functioning in pre-diagnosis Huntington disease\nAuthors: Jennifer A Ciarochi, Hans J Johnson, Vince D Calhoun, Jingyu Liu, Flor A Espinoza, Henry J Bockholt, Maria Misiura, Arvind Caprihan, Sergey Plis, Jane S Paulsen, Jessica A Turner, PREDICT-HD Investigators, Coordinators of the Huntington Study Group\nYear: 2019\nJournal: Journal of Huntington's disease\nVolume: 8\nNumber: 2\nPages: 199-219\nPublisher: IOS Press\nDescription:\nBackground: Gray matter (GM) atrophy in the striatum and across the brain is a consistently reported feature of the Huntington Disease (HD) prodrome. More recently, widespread prodromal white matter (WM) degradation has also been detected. However, longitudinal WM studies are limited and conflicting, and most analyses comparing WM and clinical functioning have also been cross-sectional.Objective: We simultaneously assessed changes in WM and cognitive and motor functioning at various prodromal HD stages. Methods: Data from 1,336 (1,047 prodromal, 289 control) PREDICT-HD participants were analyzed (3,700 sessions). MRI images were used to create GM, WM, and cerebrospinal fluid probability maps. Using source-based morphometry, independent component analysis was applied to WM probability maps to extract covarying spatial patterns and their subject profiles. WM profiles were analyzed in …\nView article\n","permalink":"http://localhost:1313/posts/concurrent-cross-sectional-and-longitudinal-analyses-of-multivariate-white-matter-profiles-and-clinical-functioning-in-pre-diagnosis-huntington-disease/","tags":["Paper","Publications"],"title":"Concurrent cross-sectional and longitudinal analyses of multivariate white matter profiles and clinical functioning in pre-diagnosis Huntington disease"},{"categories":["Publications"],"contents":"Title: Correlated noise: How it breaks NMF, and what to do about it\nAuthors: Sergey M Plis, Vamsi K Potluru, Terran Lane, Vince D Calhoun\nYear: 2011\nJournal: Journal of signal processing systems\nVolume: 65\nNumber: 3\nPages: 351-359\nPublisher: Springer US\nDescription:\nNon-negative matrix factorization (NMF) is a problem of decomposing multivariate data into a set of features and their corresponding activations. When applied to experimental data, NMF has to cope with noise, which is often highly correlated. We show that correlated noise can break the Donoho and Stodden separability conditions of a dataset and a regular NMF algorithm will fail to decompose it, even when given freedom to be able to represent the noise as a separate feature. To cope with this issue, we present an algorithm for NMF with a generalized least squares objective function (glsNMF) and derive multiplicative updates for the method together with proving their convergence. The new algorithm successfully recovers the true representation from the noisy data. Robust performance can make glsNMF a valuable tool for analyzing empirical data.\nView article\n","permalink":"http://localhost:1313/posts/correlated-noise-how-it-breaks-nmf-and-what-to-do-about-it/","tags":["Paper","Publications"],"title":"Correlated noise - How it breaks NMF, and what to do about it"},{"categories":["Publications"],"contents":"Title: Decentralized analysis of brain imaging data: Voxel-based morphometry and dynamic functional network connectivity\nAuthors: Harshvardhan Gazula, Bradley T Baker, Eswar Damaraju, Sergey M Plis, Sandeep R Panta, Rogers F Silva, Vince D Calhoun\nYear: 2018\nJournal: Frontiers in neuroinformatics\nPages: 55\nPublisher: Frontiers\nDescription:\nIn the field of neuroimaging, there is growing interest in developing collaborative frameworks that enable researchers to address challenging questions about the human brain by leveraging data across multiple sites all over the world. Additionally, efforts are also being directed at developing algorithms that enable collaborative analysis and feature learning from multiple sites without requiring the often large data to be centrally located. In this paper, we implement and evaluate two new decentralized algorithms: 1) A decentralized regression algorithm for performing a voxel-based morphometry analysis on structural magnetic resonance imaging (MRI) data and, 2) A decentralized dynamic functional network connectivity algorithm which includes decentralized group ICA and sliding-window analysis of functional MRI data. We compare results against those obtained from performing their pooled (or centralized) counterparts on the same data as if they are at one site. Results produced by the decentralized algorithms are similar to the pooled-case and showcase the potential of performing multi-voxel and multivariate analyses of data located at multiple sites. Such approaches enable many more collaborative and comparative analysis in the context of large-scale neuroimaging studies.\nView article\n","permalink":"http://localhost:1313/posts/decentralized-analysis-of-brain-imaging-data-voxel-based-morphometry-and-dynamic-functional-network-connectivity/","tags":["Paper","Publications"],"title":"Decentralized analysis of brain imaging data - Voxel-based morphometry and dynamic functional network connectivity"},{"categories":["Publications"],"contents":"Title: Decentralized distribution-sampled classification models with application to brain imaging\nAuthors: Noah Lewis, Harshvardhan Gazula, Sergey M Plis, Vince D Calhoun\nYear: 2020\nJournal: Journal of neuroscience methods\nVolume: 329\nPages: 108418\nPublisher: Elsevier\nDescription:\nIn this age of big data, certain models require very large data stores in order to be informative and accurate. In many cases however, the data are stored in separate locations requiring data transfer between local sites which can cause various practical hurdles, such as privacy concerns or heavy network load. This is especially true for medical imaging data, which can be constrained due to the health insurance portability and accountability act (HIPAA) which provides security protocols for medical data. Medical imaging datasets can also contain many thousands or millions of features, requiring heavy network load.Our research expands upon current decentralized classification research by implementing a new singleshot method for both neural networks and support vector machines. Our approach is to estimate the statistical distribution of the data at each local site and pass this information to …\nView article\n","permalink":"http://localhost:1313/posts/decentralized-distribution-sampled-classification-models-with-application-to-brain-imaging/","tags":["Paper","Publications"],"title":"Decentralized distribution-sampled classification models with application to brain imaging"},{"categories":["Publications"],"contents":"Title: Decentralized multisite VBM analysis during adolescence shows structural changes linked to age, body mass index, and smoking: a COINSTAC analysis\nAuthors: Harshvardhan Gazula, Bharath Holla, Zuo Zhang, Jiayuan Xu, Eric Verner, Ross Kelly, Sanjeev Jain, Rose Dawn Bharath, Gareth J Barker, Debasish Basu, Amit Chakrabarti, Kartik Kalyanram, Kalyanaraman Kumaran, Lenin Singh, Rebecca Kuriyan, Pratima Murthy, Vivek Benega, Sergey M Plis, Anand D Sarwate, Jessica A Turner, Gunter Schumann, Vince D Calhoun\nYear: 2021\nJournal: Neuroinformatics\nVolume: 19\nNumber: 4\nPages: 553-566\nPublisher: Springer US\nDescription:\nThere has been an upward trend in developing frameworks that enable neuroimaging researchers to address challenging questions by leveraging data across multiple sites all over the world. One such open-source framework is the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC) that works on Windows, macOS, and Linux operating systems and leverages containerized analysis pipelines to analyze neuroimaging data stored locally across multiple physical locations without the need for pooling the data at any point during the analysis. In this paper, the COINSTAC team partnered with a data collection consortium to implement the first-ever decentralized voxelwise analysis of brain imaging data performed outside the COINSTAC development group. Decentralized voxel-based morphometry analysis of over 2000 structural magnetic resonance imaging data …\nView article\n","permalink":"http://localhost:1313/posts/decentralized-multisite-vbm-analysis-during-adolescence-shows-structural-changes-linked-to-age-body-mass-index-and-smoking-a-coinstac-analysis/","tags":["Paper","Publications"],"title":"Decentralized multisite VBM analysis during adolescence shows structural changes linked to age, body mass index, and smoking - a COINSTAC analysis"},{"categories":["Publications"],"contents":"Title: Decentralized temporal independent component analysis: leveraging fMRI data in collaborative settings\nAuthors: Bradley T Baker, Anees Abrol, Rogers F Silva, Eswar Damaraju, Anand D Sarwate, Vince D Calhoun, Sergey M Plis\nYear: 2019\nJournal: NeuroImage\nVolume: 186\nPages: 557-569\nPublisher: Academic Press\nDescription:\nThe field of neuroimaging has recently witnessed a strong shift towards data sharing; however, current collaborative research projects may be unable to leverage institutional architectures that collect and store data in local, centralized data centers. Additionally, though research groups are willing to grant access for collaborations, they often wish to maintain control of their data locally. These concerns may stem from research culture as well as privacy and accountability concerns. In order to leverage the potential of these aggregated larger data sets, we require tools that perform joint analyses without transmitting the data. Ideally, these tools would have similar performance and ease of use as their current centralized counterparts. In this paper, we propose and evaluate a new Algorithm, decentralized joint independent component analysis (djICA), which meets these technical requirements. djICA shares only …\nView article\n","permalink":"http://localhost:1313/posts/decentralized-temporal-independent-component-analysis-leveraging-fmri-data-in-collaborative-settings/","tags":["Paper","Publications"],"title":"Decentralized temporal independent component analysis - leveraging fMRI data in collaborative settings"},{"categories":["Publications"],"contents":"Title: Deep independence network analysis of structural brain imaging: application to schizophrenia\nAuthors: Eduardo Castro, R Devon Hjelm, Sergey M Plis, Laurent Dinh, Jessica A Turner, Vince D Calhoun\nYear: 2016\nJournal: IEEE transactions on medical imaging\nVolume: 35\nNumber: 7\nPages: 1729-1740\nPublisher: IEEE\nDescription:\nLinear independent component analysis (ICA) is a standard signal processing technique that has been extensively used on neuroimaging data to detect brain networks with coherent brain activity (functional MRI) or covarying structural patterns (structural MRI). However, its formulation assumes that the measured brain signals are generated by a linear mixture of the underlying brain networks and this assumption limits its ability to detect the inherent nonlinear nature of brain interactions. In this paper, we introduce nonlinear independent component estimation (NICE) to structural MRI data to detect abnormal patterns of gray matter concentration in schizophrenia patients. For this biomedical application, we further addressed the issue of model regularization of nonlinear ICA by performing dimensionality reduction prior to NICE, together with an appropriate control of the complexity of the model and the usage of a …\nView article\n","permalink":"http://localhost:1313/posts/deep-independence-network-analysis-of-structural-brain-imaging-application-to-schizophrenia/","tags":["Paper","Publications"],"title":"Deep independence network analysis of structural brain imaging- application to schizophrenia"},{"categories":["Publications"],"contents":"Title: Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data\nAuthors: Alexander Aliper, Sergey Plis, Artem Artemov, Alvaro Ulloa, Polina Mamoshina, Alex Zhavoronkov\nYear: 2016\nJournal: Molecular pharmaceutics\nVolume: 13\nNumber: 7\nPages: 2524-2530\nPublisher: American Chemical Society\nDescription:\nDeep learning is rapidly advancing many areas of science and technology with multiple success stories in image, text, voice and video recognition, robotics, and autonomous driving. In this paper we demonstrate how deep neural networks (DNN) trained on large transcriptional response data sets can classify various drugs to therapeutic categories solely based on their transcriptional profiles. We used the perturbation samples of 678 drugs across A549, MCF-7, and PC-3 cell lines from the LINCS Project and linked those to 12 therapeutic use categories derived from MeSH. To train the DNN, we utilized both gene level transcriptomic data and transcriptomic data processed using a pathway activation scoring algorithm, for a pooled data set of samples perturbed with different concentrations of the drug for 6 and 24 hours. In both pathway and gene level classification, DNN achieved high classification accuracy and …\nView article\n","permalink":"http://localhost:1313/posts/deep-learning-applications-for-predicting-pharmacological-properties-of-drugs-and-drug-repurposing-using-transcriptomic-data/","tags":["Paper","Publications"],"title":"Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data"},{"categories":["Publications"],"contents":"Title: Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning\nAuthors: Anees Abrol, Zening Fu, Mustafa Salman, Rogers Silva, Yuhui Du, Sergey Plis, Vince Calhoun\nYear: 2021\nJournal: Nature communications\nVolume: 12\nNumber: 1\nPages: 1-17\nPublisher: Nature Publishing Group\nDescription:\nRecent critical commentaries unfavorably compare deep learning (DL) with standard machine learning (SML) approaches for brain imaging data analysis. However, their conclusions are often based on pre-engineered features depriving DL of its main advantage — representation learning. We conduct a large-scale systematic comparison profiled in multiple classification and regression tasks on structural MRI images and show the importance of representation learning for DL. Results show that if trained following prevalent DL practices, DL methods have the potential to scale particularly well and substantially improve compared to SML methods, while also presenting a lower asymptotic complexity in relative computational time, despite being more complex. We also demonstrate that DL embeddings span comprehensible task-specific projection spectra and that DL consistently localizes task-discriminative brain …\nView article\n","permalink":"http://localhost:1313/posts/deep-learning-encodes-robust-discriminative-neuroimaging-representations-to-outperform-standard-machine-learning/","tags":["Paper","Publications"],"title":"Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning"},{"categories":["Publications"],"contents":"Title: Deep learning for neuroimaging: a validation study\nAuthors: Sergey M Plis, Devon R Hjelm, Ruslan Salakhutdinov, Elena A Allen, Henry J Bockholt, Jeffrey D Long, Hans J Johnson, Jane S Paulsen, Jessica A Turner, Vince D Calhoun\nYear: 2014\nJournal: Frontiers in neuroscience\nVolume: 8\nPages: 229\nPublisher: Frontiers Media SA\nDescription:\nDeep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.\nView article\n","permalink":"http://localhost:1313/posts/deep-learning-for-neuroimaging-a-validation-study/","tags":["Paper","Publications"],"title":"Deep learning for neuroimaging - a validation study"},{"categories":["Publications"],"contents":"Title: Deep learning models for brain imaging: Model depth enhances discovery power\nAuthors: SM Plis, RD Hjelm, RR Salakhutdinov, VD Calhoun\nYear: 2014\nJournal: Proceedings of the Organization of Human Brain Mapping Annual Meeting, June\nPages: 8-12\nDescription:\nDeep learning methods are breaking records in the areas of speech, signal, image, video and text mining and recognition by improving state of the art classification accuracy by, sometimes, more than 30% where the prior decade struggled to obtain a 1-2% improvements [1]. These are very important tasks for brain imaging and neuroscience discovery. In this work we demonstrate our results in application of deep learning methods to brain imaging data from schizophrenia and Huntington disease studies. Our results show: automatic feature learning and model depth enable detection of latent relations in neuroimaging data and improve discriminative power.\nView article\n","permalink":"http://localhost:1313/posts/deep-learning-models-for-brain-imaging-model-depth-enhances-discovery-power/","tags":["Paper","Publications"],"title":"Deep learning models for brain imaging - Model depth enhances discovery power"},{"categories":["Publications"],"contents":"Title: Deep residual learning for neuroimaging: an application to predict progression to Alzheimer’s disease\nAuthors: Anees Abrol, Manish Bhattarai, Alex Fedorov, Yuhui Du, Sergey Plis, Vince Calhoun, Alzheimer’s Disease Neuroimaging Initiative\nYear: 2020\nJournal: Journal of neuroscience methods\nVolume: 339\nPages: 108701\nPublisher: Elsevier\nDescription:\nThe unparalleled performance of deep learning approaches in generic image processing has motivated its extension to neuroimaging data. These approaches learn abstract neuroanatomical and functional brain alterations that could enable exceptional performance in classification of brain disorders, predicting disease progression, and localizing brain abnormalities.This work investigates the suitability of a modified form of deep residual neural networks (ResNet) for studying neuroimaging data in the specific application of predicting progression from mild cognitive impairment (MCI) to Alzheimer’s disease (AD). Prediction was conducted first by training the deep models using MCI individuals only, followed by a domain transfer learning version that additionally trained on AD and controls. We also demonstrate a network occlusion based method to localize abnormalities.The …\nView article\n","permalink":"http://localhost:1313/posts/deep-residual-learning-for-neuroimaging-an-application-to-predict-progression-to-alzheimer%CE%B3%C3%A7%C3%B6s-disease/","tags":["Paper","Publications"],"title":"Deep residual learning for neuroimaging - an application to predict progression to Alzheimer's disease"},{"categories":["Publications"],"contents":"Title: Detecting Label Noise from Multi-site Structural Magnetic Resonance Imaging Data to Mitigate Inaccurate Nosology in Mental Health\nAuthors: Hooman Rokham, Haleh Falakshahi, Sergey Plis, Vince Calhoun\nYear: 2020\nJournal: Biological Psychiatry\nVolume: 87\nNumber: 9\nPages: S269\nPublisher: Elsevier\nDescription:\nBackgroundCategorizing mental disorders is typically based on symptom-based measures which have large overlaps in clinical symptoms and biological measures among different diagnosis groups. Inaccurate labeling decreases reliability of approaches which build models based on input categorized data. Understanding and addressing this issue is important to improve diagnostic classification.MethodsWe used a novel classification-voting filtering method to identify mislabeled subjects based on a structural MRI dataset. We applied an ANOVA F-value feature selection for dimension reduction and grid search for hyper-parameters optimization. We used iterative support vector machine classification voting filtering to detect label noise by classifying structural MRI (sMRI) data multiple times with the cross-validation stage. New model trained using remaining cleansed data and suggested new labels for misclassified …\nView article\n","permalink":"http://localhost:1313/posts/detecting-label-noise-from-multi-site-structural-magnetic-resonance-imaging-data-to-mitigate-inaccurate-nosology-in-mental-health/","tags":["Paper","Publications"],"title":"Detecting Label Noise from Multi-site Structural Magnetic Resonance Imaging Data to Mitigate Inaccurate Nosology in Mental Health"},{"categories":["Publications"],"contents":"Title: Directional statistics on permutations\nAuthors: Sergey M Plis, Terran Lane, Vince D Calhoun\nYear: 2010\nJournal: arXiv preprint arXiv:1007.2450\nDescription:\nDistributions over permutations arise in applications ranging from multi-object tracking to ranking of instances. The difficulty of dealing with these distributions is caused by the size of their domain, which is factorial in the number of considered entities (). It makes the direct definition of a multinomial distribution over permutation space impractical for all but a very small . In this work we propose an embedding of all permutations for a given in a surface of a hypersphere defined in $\\mathbbm{R}^{(n-1)^2}$. As a result of the embedding, we acquire ability to define continuous distributions over a hypersphere with all the benefits of directional statistics. We provide polynomial time projections between the continuous hypersphere representation and the -element permutation space. The framework provides a way to use continuous directional probability densities and the methods developed thereof for establishing densities over permutations. As a demonstration of the benefits of the framework we derive an inference procedure for a state-space model over permutations. We demonstrate the approach with applications.\nView article\n","permalink":"http://localhost:1313/posts/directional-statistics-on-permutations/","tags":["Paper","Publications"],"title":"Directional statistics on permutations"},{"categories":["Publications"],"contents":"Title: Disrupted correlation between low frequency power and connectivity strength of resting state brain networks in schizophrenia\nAuthors: Qingbao Yu, Jing Sui, Jingyu Liu, Sergey M Plis, Kent A Kiehl, Godfrey Pearlson, Vince D Calhoun\nYear: 2013\nJournal: Schizophrenia research\nVolume: 143\nNumber: 1\nPages: 165-171\nPublisher: Elsevier\nDescription:\nAltered brain connectivity has emerged as a central feature of schizophrenia. Low frequency oscillations and connectivity strength (CS) of resting state brain networks are altered in patients with schizophrenia (SZs). However, the relationship between these two measures has not yet been studied. Such work may be helpful in understanding the so-called “rich club” organization (i.e. high-CS nodes are more densely connected among themselves than are nodes of a lower CS in the human brain) in healthy controls (HCs) and SZs. Here we present a study of HCs and SZs examining low frequency oscillations and CS by first decomposing resting state fMRI (R-fMRI) data into independent components (ICs) using group independent component analysis (ICA) and computing the low frequency power ratio (LFPR) of each ICA time course. Weighted brain graphs consisting of ICs were built based on correlations between …\nView article\n","permalink":"http://localhost:1313/posts/disrupted-correlation-between-low-frequency-power-and-connectivity-strength-of-resting-state-brain-networks-in-schizophrenia/","tags":["Paper","Publications"],"title":"Disrupted correlation between low frequency power and connectivity strength of resting state brain networks in schizophrenia"},{"categories":["Publications"],"contents":"Title: dSNE: a visualization approach for use with decentralized data\nAuthors: Debbrata K Saha, VD Calhoun, D Yuhui, F Zening, Sandeep R Panta, SM Plis\nYear: 2019\nJournal: BioRxiv\nPages: 826974\nDescription:\nVisualization of high dimensional large-scale datasets via an embedding into a 2D map is a powerful exploration tool for assessing latent structure in the data and detecting outliers. It plays a vital role in neuroimaging field because sometimes it is the only way to perform quality control of large dataset. There are many methods developed to perform this task but most of them rely on the assumption that all samples are locally available for the computation. Specifically, one needs access to all the samples in order to compute the distance directly between all pairs of points to measure the similarity. But all pairs of samples may not be available locally always from local sites for various reasons (eg privacy concerns for rare disease data, institutional or IRB policies). This is quite common for biomedical data, eg neuroimaging and genetic, where privacypreservation is a major concern. In this scenario, a quality control tool that visualizes decentralized dataset in its entirety via global aggregation of local computations is especially important as it would allow screening of samples that cannot be evaluated otherwise. We introduced an algorithm to solve this problem: decentralized data stochastic neighbor embedding (dSNE). In our approach, data samples (ie brain images) located at different sites are simultaneously mapped into the same space according to their similarities. Yet, the data never leaves the individual sites and no pairwise metric is ever directly computed between any two samples not collocated. Based on the Modified\nView article\n","permalink":"http://localhost:1313/posts/dsne-a-visualization-approach-for-use-with-decentralized-data/","tags":["Paper","Publications"],"title":"dSNE - a visualization approach for use with decentralized data"},{"categories":["Publications"],"contents":"Title: Effective connectivity analysis of fMRI and MEG data collected under identical paradigms\nAuthors: Sergey M Plis, Michael P Weisend, Eswar Damaraju, Tom Eichele, Andy Mayer, Vincent P Clark, Terran Lane, Vince D Calhoun\nYear: 2011\nJournal: Computers in biology and medicine\nVolume: 41\nNumber: 12\nPages: 1156-1165\nPublisher: Pergamon\nDescription:\nEstimation of effective connectivity, a measure of the influence among brain regions, can potentially reveal valuable information about organization of brain networks. Effective connectivity is usually evaluated from the functional data of a single modality. In this paper we show why that may lead to incorrect conclusions about effective connectivity. In this paper we use Bayesian networks to estimate connectivity on two different modalities. We analyze structures of estimated effective connectivity networks using aggregate statistics from the field of complex networks. Our study is conducted on functional MRI and magnetoencephalography data collected from the same subjects under identical paradigms. Results showed some similarities but also revealed some striking differences in the conclusions one would make on the fMRI data compared with the MEG data and are strongly supportive of the use of multiple …\nView article\n","permalink":"http://localhost:1313/posts/effective-connectivity-analysis-of-fmri-and-meg-data-collected-under-identical-paradigms/","tags":["Paper","Publications"],"title":"Effective connectivity analysis of fMRI and MEG data collected under identical paradigms"},{"categories":["Publications"],"contents":"Title: Efficient Distributed Auto-Differentiation\nAuthors: Bradley T Baker, Vince D Calhoun, Barak Pearlmutter, Sergey M Plis\nYear: 2021\nJournal: arXiv preprint arXiv:2102.09631\nDescription:\nAlthough distributed machine learning has opened up numerous frontiers of research, the separation of large models across different devices, nodes, and sites can invite significant communication overhead, making reliable training difficult. The focus on gradients as the primary shared statistic during training has led to a number of intuitive algorithms for distributed deep learning; however, gradient-based algorithms for training large deep neural networks (DNNs) are communication-heavy, often requiring additional modifications via sparsity constraints, compression, quantization, and other similar approaches, to lower bandwidth. We introduce a surprisingly simple statistic for training distributed DNNs that is more communication-friendly than the gradient. The error backpropagation process can be modified to share these smaller intermediate values instead of the gradient, reducing communication overhead with no impact on accuracy. The process provides the flexibility of averaging gradients during backpropagation, enabling novel flexible training schemas while leaving room for further bandwidth reduction via existing gradient compression methods. Finally, consideration of the matrices used to compute the gradient inspires a new approach to compression via structured power iterations, which can not only reduce bandwidth but also enable introspection into distributed training dynamics, without significant performance loss.\nView article\n","permalink":"http://localhost:1313/posts/efficient-distributed-auto-differentiation/","tags":["Paper","Publications"],"title":"Efficient Distributed Auto-Differentiation"},{"categories":["Publications"],"contents":"Title: Explicit group sparse projection with applications to deep learning and NMF\nAuthors: Riyasat Ohib, Nicolas Gillis, Niccolò Dalmasso, Sameena Shah, Vamsi K Potluru, Sergey Plis\nYear: 2019\nJournal: Transactions on Machine Learning Research\nDescription:\nWe design a new sparse projection method for a set of vectors that guarantees a desired average sparsity level measured leveraging the popular Hoyer measure (an affine function of the ratio of the and norms). Existing approaches either project each vector individually or require the use of a regularization parameter which implicitly maps to the average -measure of sparsity. Instead, in our approach we set the sparsity level for the whole set explicitly and simultaneously project a group of vectors with the sparsity level of each vector tuned automatically. We show that the computational complexity of our projection operator is linear in the size of the problem. Additionally, we propose a generalization of this projection by replacing the norm by its weighted version. We showcase the efficacy of our approach in both supervised and unsupervised learning tasks on image datasets including CIFAR10 and ImageNet. In deep neural network pruning, the sparse models produced by our method on ResNet50 have significantly higher accuracies at corresponding sparsity values compared to existing competitors. In nonnegative matrix factorization, our approach yields competitive reconstruction errors against state-of-the-art algorithms.\nView article\n","permalink":"http://localhost:1313/posts/explicit-group-sparse-projection-with-applications-to-deep-learning-and-nmf/","tags":["Paper","Publications"],"title":"Explicit group sparse projection with applications to deep learning and NMF"},{"categories":["Publications"],"contents":"Title: From private sites to big data without compromising privacy: a case of neuroimaging data classification\nAuthors: S Plis, A Sarwate, J Turner, M Arbabshirani, V Calhoun\nYear: 2014\nJournal: Value in Health\nVolume: 17\nNumber: 3\nPages: A190\nPublisher: Elsevier\nDescription:\nObjectivesOpen data sharing for large-scale studies is an expensive and resource-wasteful approach that does not scale well with participating sites. Critically, some data simply cannot be shared due to privacy concerns and/or risk of re-identification. We pursue distributed computation that only shares data derivatives, such as statistical summaries, as a notable alternative allowing data holders to maintain control over data access. Privacy protection, if implemented via the differential privacy framework, can quantify and controllably reduce the risk of sharing the results of computations on private data. Unfortunately, it can impair the quality of statistical estimates at a single site. Using structural MRI data we present a distributed differentially private classifier that greatly improves the accuracy.MethodsWe used a combined MRI dataset from four separate schizophrenia studies conducted at Johns Hopkins University …\nView article\n","permalink":"http://localhost:1313/posts/from-private-sites-to-big-data-without-compromising-privacy-a-case-of-neuroimaging-data-classification/","tags":["Paper","Publications"],"title":"From private sites to big data without compromising privacy - a case of neuroimaging data classification"},{"categories":["Publications"],"contents":"Title: Functional and effective connectivity of stopping\nAuthors: René J Huster, Sergey M Plis, Christina F Lavallee, Vince D Calhoun, Christoph S Herrmann\nYear: 2014\nJournal: Neuroimage\nVolume: 94\nPages: 120-128\nPublisher: Academic Press\nDescription:\nBehavioral inhibition often is studied by comparing the electroencephalographic responses to stop and to go signals. Most studies simply assess amplitude differences of the N200 and P300 event-related potentials, which seem to best correspond to increased activity in the theta and delta frequency bands, respectively. However, neither have reliable indicators for successful behavioral inhibition been identified nor have the causal dependencies of stop-related neurocognitive processes been addressed yet. By studying functional and effective connectivity underlying stopping behavior, this study opens new directions for the investigation of behavioral inhibition. Group independent component analysis was used to infer functionally coherent networks from electroencephalographic data, which were recorded from healthy human participants during processing of a stop signal task. Then, the temporal dynamics of …\nView article\n","permalink":"http://localhost:1313/posts/functional-and-effective-connectivity-of-stopping/","tags":["Paper","Publications"],"title":"Functional and effective connectivity of stopping"},{"categories":["Publications"],"contents":"Title: Group-level component analyses of EEG: validation and evaluation\nAuthors: Rene J Huster, Sergey M Plis, Vince D Calhoun\nYear: 2015\nJournal: Frontiers in neuroscience\nVolume: 9\nPages: 254\nPublisher: Frontiers Media SA\nDescription:\nMulti-subject or group-level component analysis provides a data-driven approach to study properties of brain networks. Algorithms for group-level data decomposition of functional magnetic resonance imaging data have been brought forward more than a decade ago and have significantly matured since. Similar applications for electroencephalographic data are at a comparatively early stage of development though, and their sensitivity to topographic variability of the electroencephalogram or loose time-locking of neuronal responses has not yet been assessed. This study investigates the performance of independent component analysis (ICA) and second order blind source identification (SOBI) for data decomposition, and their combination with either temporal or spatial concatenation of data sets, for multi-subject analyses of electroencephalographic data. \\indent Analyses of simulated sources with different spatial, frequency, and time-locking profiles, revealed that temporal concatenation of data sets with either ICA or SOBI served well to reconstruct sources with both strict and loose time-locking, whereas performance decreased in the presence of topographical variability. The opposite pattern was found with a spatial concatenation of subject-specific data sets. This study proofs that procedures for group-level decomposition of electroencephalographic data can be considered valid and promising approaches to infer the latent structure of multi-subject data sets. Yet, specific implementations need further adaptations to optimally address sources of inter-subject and inter-trial variance commonly found in EEG recordings.\nView article\n","permalink":"http://localhost:1313/posts/group-level-component-analyses-of-eeg-validation-and-evaluation/","tags":["Paper","Publications"],"title":"Group-level component analyses of EEG - validation and evaluation"},{"categories":["Publications"],"contents":"Title: Grouped sparse projection\nAuthors: Nicolas Gillis, Riyasat Ohib, Sergey Plis, Vamsi Potluru\nYear: 2019\nJournal: arXiv preprint arXiv:1912.03896\nDescription:\nAs evident from deep learning, very large models bring improvements in training dynamics and representation power. Yet, smaller models have benefits of energy efficiency and interpretability. To get the benefits from both ends of the spectrum we often encourage sparsity in the model. Unfortunately, most existing approaches do not have a controllable way to request a desired value of sparsity in an interpretable parameter. In this paper, we design a new sparse projection method for a set of vectors in order to achieve a desired average level of sparsity which is measured using the ratio of the and norms. Most existing methods project each vector individuality trying to achieve a target sparsity, hence the user has to choose a sparsity level for each vector (e.g., impose that all vectors have the same sparsity). Instead, we project all vectors together to achieve an average target sparsity, where the sparsity levels of the vectors is automatically tuned. We also propose a generalization of this projection using a new notion of weighted sparsity measured using the ratio of a weighted and the norms. These projections can be used in particular to sparsify the columns of a matrix, which we use to compute sparse nonnegative matrix factorization and to learn sparse deep networks.\nView article\n","permalink":"http://localhost:1313/posts/grouped-sparse-projection/","tags":["Paper","Publications"],"title":"Grouped sparse projection"},{"categories":["Publications"],"contents":"Title: High and Low Levels of an NTRK2-Driven Genetic Profile Affect Motor- and Cognition-Associated Frontal Gray Matter in Prodromal Huntington’s Disease\nAuthors: Jennifer A Ciarochi, Jingyu Liu, Vince Calhoun, Hans Johnson, Maria Misiura, H Jeremy Bockholt, Flor A Espinoza, Arvind Caprihan, Sergey Plis, Jessica A Turner, Jane S Paulsen, PREDICT-HD Investigators, Coordinators of the Huntington Study Group\nYear: 2018\nJournal: Brain sciences\nVolume: 8\nNumber: 7\nPages: 116\nPublisher: MDPI\nDescription:\nThis study assessed how BDNF (brain-derived neurotrophic factor) and other genes involved in its signaling influence brain structure and clinical functioning in pre-diagnosis Huntington’s disease (HD). Parallel independent component analysis (pICA), a multivariate method for identifying correlated patterns in multimodal datasets, was applied to gray matter concentration (GMC) and genomic data from a sizeable PREDICT-HD prodromal cohort (N = 715). pICA identified a genetic component highlighting NTRK2, which encodes BDNF’s TrkB receptor, that correlated with a GMC component including supplementary motor, precentral/premotor cortex, and other frontal areas (p \u0026lt; 0.001); this association appeared to be driven by participants with high or low levels of the genetic profile. The frontal GMC profile correlated with cognitive and motor variables (Trail Making Test A (p = 0.03); Stroop Color (p = 0.017); Stroop Interference (p = 0.04); Symbol Digit Modalities Test (p = 0.031); Total Motor Score (p = 0.01)). A top-weighted NTRK2 variant (rs2277193) was protectively associated with Trail Making Test B (p = 0.007); greater minor allele numbers were linked to a better performance. These results support the idea of a protective role of NTRK2 in prodromal HD, particularly in individuals with certain genotypes, and suggest that this gene may influence the preservation of frontal gray matter that is important for clinical functioning.\nView article\n","permalink":"http://localhost:1313/posts/high-and-low-levels-of-an-ntrk2-driven-genetic-profile-affect-motor--and-cognition-associated-frontal-gray-matter-in-prodromal-huntington%CE%B3%C3%A7%C3%B6s-disease/","tags":["Paper","Publications"],"title":"High and Low Levels of an NTRK2-Driven Genetic Profile Affect Motor- and Cognition-Associated Frontal Gray Matter in Prodromal Huntington’s Disease"},{"categories":["Publications"],"contents":"Title: High-order interactions observed in multi-task intrinsic networks are dominant indicators of aberrant brain function in schizophrenia\nAuthors: Sergey M Plis, Jing Sui, Terran Lane, Sushmita Roy, Vincent P Clark, Vamsi K Potluru, Rene J Huster, Andrew Michael, Scott R Sponheim, Michael P Weisend, Vince D Calhoun\nYear: 2014\nJournal: NeuroImage\nVolume: 102\nPages: 35-48\nPublisher: Academic Press\nDescription:\nIdentifying the complex activity relationships present in rich, modern neuroimaging data sets remains a key challenge for neuroscience. The problem is hard because (a) the underlying spatial and temporal networks may be nonlinear and multivariate and (b) the observed data may be driven by numerous latent factors. Further, modern experiments often produce data sets containing multiple stimulus contexts or tasks processed by the same subjects. Fusing such multi-session data sets may reveal additional structure, but raises further statistical challenges. We present a novel analysis method for extracting complex activity networks from such multifaceted imaging data sets. Compared to previous methods, we choose a new point in the trade-off space, sacrificing detailed generative probability models and explicit latent variable inference in order to achieve robust estimation of multivariate, nonlinear group factors …\nView article\n","permalink":"http://localhost:1313/posts/high-order-interactions-observed-in-multi-task-intrinsic-networks-are-dominant-indicators-of-aberrant-brain-function-in-schizophrenia/","tags":["Paper","Publications"],"title":"High-order interactions observed in multi-task intrinsic networks are dominant indicators of aberrant brain function in schizophrenia"},{"categories":["Publications"],"contents":"Title: Hype versus hope: deep learning encodes more predictive and robust brain imaging representations than standard machine learning\nAuthors: Anees Abrol, Zening Fu, Mustafa Salman, Rogers Silva, Yuhui Du, Sergey Plis, Vince Calhoun\nYear: 2020\nJournal: BioRxiv\nPublisher: Cold Spring Harbor Laboratory\nDescription:\nPrevious successes of deep learning (DL) approaches on several complex tasks have hugely inflated expectations of their power to learn subtle properties of complex brain imaging data, and scale to large datasets. Perhaps as a reaction to this inflation, recent critical commentaries unfavorably compare DL with standard machine learning (SML) approaches for the analysis of brain imaging data. Yet, their conclusions are based on pre-engineered features which deprives DL of its main advantage: representation learning. Here we evaluate this and show the importance of representation learning for DL performance on brain imaging data. We report our findings from a large-scale systematic comparison of SML approaches versus DL profiled in a ten-way age and gender-based classification task on 12,314 structural MRI images. Results show that DL methods, if implemented and trained following the prevalent DL practices, have the potential to substantially improve compared to SML approaches. We also show that DL approaches scale particularly well presenting a lower asymptotic complexity in relative computational time, despite being more complex. Our analysis reveals that the performance improvement saturates as the training sample size grows, but shows significantly higher performance throughout. We also show evidence that the superior performance of DL is primarily due to the excellent representation learning capabilities and that SML methods can perform equally well when operating on representations produced by the trained DL models. Finally, we demonstrate that DL embeddings span a comprehensible projection spectrum and …\nView article\n","permalink":"http://localhost:1313/posts/hype-versus-hope-deep-learning-encodes-more-predictive-and-robust-brain-imaging-representations-than-standard-machine-learning/","tags":["Paper","Publications"],"title":"Hype versus hope - deep learning encodes more predictive and robust brain imaging representations than standard machine learning"},{"categories":["Publications"],"contents":"Title: Impact of autocorrelation on functional connectivity\nAuthors: Mohammad R Arbabshirani, Eswar Damaraju, Ronald Phlypo, Sergey Plis, Elena Allen, Sai Ma, Daniel Mathalon, Adrian Preda, Jatin G Vaidya, Tülay Adali, Vince D Calhoun\nYear: 2014\nJournal: Neuroimage\nVolume: 102\nPages: 294-308\nPublisher: Academic Press\nDescription:\nAlthough the impact of serial correlation (autocorrelation) in residuals of general linear models for fMRI time-series has been studied extensively, the effect of autocorrelation on functional connectivity studies has been largely neglected until recently. Some recent studies based on results from economics have questioned the conventional estimation of functional connectivity and argue that not correcting for autocorrelation in fMRI time-series results in “spurious” correlation coefficients. In this paper, first we assess the effect of autocorrelation on Pearson correlation coefficient through theoretical approximation and simulation. Then we present this effect on real fMRI data. To our knowledge this is the first work comprehensively investigating the effect of autocorrelation on functional connectivity estimates. Our results show that although FC values are altered, even following correction for autocorrelation, results of …\nView article\n","permalink":"http://localhost:1313/posts/impact-of-autocorrelation-on-functional-connectivity/","tags":["Paper","Publications"],"title":"Impact of autocorrelation on functional connectivity"},{"categories":["Publications"],"contents":"Title: Improved differentially private decentralized source separation for fMRI data\nAuthors: Hafiz Imtiaz, Jafar Mohammadi, Rogers Silva, Bradley Baker, Sergey M Plis, Anand D Sarwate, Vince Calhoun\nYear: 2019\nJournal: arXiv preprint arXiv:1910.12913\nDescription:\nBlind source separation algorithms such as independent component analysis (ICA) are widely used in the analysis of neuroimaging data. In order to leverage larger sample sizes, different data holders/sites may wish to collaboratively learn feature representations. However, such datasets are often privacy-sensitive, precluding centralized analyses that pool the data at a single site. In this work, we propose a differentially private algorithm for performing ICA in a decentralized data setting. Conventional approaches to decentralized differentially private algorithms may introduce too much noise due to the typically small sample sizes at each site. We propose a novel protocol that uses correlated noise to remedy this problem. We show that our algorithm outperforms existing approaches on synthetic and real neuroimaging datasets and demonstrate that it can sometimes reach the same level of utility as the corresponding non-private algorithm. This indicates that it is possible to have meaningful utility while preserving privacy.\nView article\n","permalink":"http://localhost:1313/posts/improved-differentially-private-decentralized-source-separation-for-fmri-data/","tags":["Paper","Publications"],"title":"Improved differentially private decentralized source separation for fMRI data"},{"categories":["Publications"],"contents":"Title: Improving classification rate of schizophrenia using a multimodal multi-layer perceptron model with structural and functional MR\nAuthors: Alvaro Ulloa, Sergey Plis, Vince Calhoun\nYear: 2018\nJournal: arXiv preprint arXiv:1804.04591\nDescription:\nThe wide variety of brain imaging technologies allows us to exploit information inherent to different data modalities. The richness of multimodal datasets may increase predictive power and reveal latent variables that otherwise would have not been found. However, the analysis of multimodal data is often conducted by assuming linear interactions which impact the accuracy of the results. We propose the use of a multimodal multi-layer perceptron model to enhance the predictive power of structural and functional magnetic resonance imaging (sMRI and fMRI) combined. We also use a synthetic data generator to pre-train each modality input layers, alleviating the effects of the small sample size that is often the case for brain imaging modalities. The proposed model improved the average and uncertainty of the area under the ROC curve to 0.850+-0.051 compared to the best results on individual modalities (0.741+-0.075 for sMRI, and 0.833+-0.050 for fMRI).\nView article\n","permalink":"http://localhost:1313/posts/improving-classification-rate-of-schizophrenia-using-a-multimodal-multi-layer-perceptron-model-with-structural-and-functional-mr/","tags":["Paper","Publications"],"title":"Improving classification rate of schizophrenia using a multimodal multi-layer perceptron model with structural and functional MR"},{"categories":["Publications"],"contents":"Title: Improving source detection and separation in a spatiotemporal Bayesian inference dipole analysis\nAuthors: Sung C Jun, John S George, Sergey M Plis, Doug M Ranken, David M Schmidt, CC Wood\nYear: 2006\nJournal: Physics in Medicine \u0026amp; Biology\nVolume: 51\nNumber: 10\nPages: 2395\nPublisher: IOP Publishing\nDescription:\nMost existing spatiotemporal multi-dipole approaches for MEG/EEG source localization assume that the dipoles are active for the full time range being analysed. If the actual time range of activity of sources is significantly shorter than the time range being analysed, the detectability, localization and time-course determination of such sources may be adversely affected, especially for weak sources. In order to improve detectability and reconstruction of such sources, it is natural to add active time range information (starting time point and ending time point of source activation) for each candidate source as unknown parameters in the analysis. However, this adds additional nonlinear free parameters that could burden the analysis and could be unfeasible for some methods. Recently, we described a spatiotemporal Bayesian inference multi-dipole analysis for the MEG/EEG inverse problem. This approach treated the …\nView article\n","permalink":"http://localhost:1313/posts/improving-source-detection-and-separation-in-a-spatiotemporal-bayesian-inference-dipole-analysis/","tags":["Paper","Publications"],"title":"Improving source detection and separation in a spatiotemporal Bayesian inference dipole analysis"},{"categories":["Publications"],"contents":"Title: Independent component analysis for brain fMRI does indeed select for maximal independence\nAuthors: Vince D Calhoun, Vamsi K Potluru, Ronald Phlypo, Rogers F Silva, Barak A Pearlmutter, Arvind Caprihan, Sergey M Plis, Tülay Adalı\nYear: 2013\nJournal: PloS one\nVolume: 8\nNumber: 8\nPages: e73309\nPublisher: Public Library of Science\nDescription:\nA recent paper by Daubechies et al. claims that two independent component analysis (ICA) algorithms, Infomax and FastICA, which are widely used for functional magnetic resonance imaging (fMRI) analysis, select for sparsity rather than independence. The argument was supported by a series of experiments on synthetic data. We show that these experiments fall short of proving this claim and that the ICA algorithms are indeed doing what they are designed to do: identify maximally independent sources.\nView article\n","permalink":"http://localhost:1313/posts/independent-component-analysis-for-brain-fmri-does-indeed-select-for-maximal-independence/","tags":["Paper","Publications"],"title":"Independent component analysis for brain fMRI does indeed select for maximal independence"},{"categories":["Publications"],"contents":"Title: Learning dynamic structure from undersampled data\nAuthors: John W Cook, David Danks, Sergey M Plis\nYear: 2017\nJournal: Proceedings of the UAI Causality Workshop\nDescription:\nMost causal learning algorithms for time series data assume that the underlying generative process operates on approximately the same timescale as the measurement process (or that any differences do not impede learning). This assumption fails in many domains, and so we first show that undersampling creates learning challenges at the measurement timescale, even for simple generative processes. We then describe four algorithmic generalizations (some previously proposed, none previously tested)—two for continuous data, and two for either continuous or discrete data—and test them on simulated data. The results suggest that measurement timescale structure learning from undersampled time series data is feasible, but the appropriate model class needs to be used. Moreover, explicitly representing the possibility of undersampling can yield valuable regularization benefits.\nView article\n","permalink":"http://localhost:1313/posts/learning-dynamic-structure-from-undersampled-data/","tags":["Paper","Publications"],"title":"Learning dynamic structure from undersampled data"},{"categories":["Publications"],"contents":"Title: Learnt dynamics generalizes across tasks, datasets, and populations\nAuthors: Usman Mahmood, Md Mahfuzur Rahman, Alex Fedorov, Zening Fu, Vince D Calhoun, Sergey M Plis\nYear: 2019\nJournal: arXiv preprint arXiv:1912.03130\nDescription:\nDifferentiating multivariate dynamic signals is a difficult learning problem as the feature space may be large yet often only a few training examples are available. Traditional approaches to this problem either proceed from handcrafted features or require large datasets to combat the m \u0026gt;\u0026gt; n problem. In this paper, we show that the source of the problem\u0026mdash;signal dynamics\u0026mdash;can be used to our advantage and noticeably improve classification performance on a range of discrimination tasks when training data is scarce. We demonstrate that self-supervised pre-training guided by signal dynamics produces embedding that generalizes across tasks, datasets, data collection sites, and data distributions. We perform an extensive evaluation of this approach on a range of tasks including simulated data, keyword detection problem, and a range of functional neuroimaging data, where we show that a single embedding learnt on healthy subjects generalizes across a number of disorders, age groups, and datasets.\nView article\n","permalink":"http://localhost:1313/posts/learnt-dynamics-generalizes-across-tasks-datasets-and-populations/","tags":["Paper","Publications"],"title":"Learnt dynamics generalizes across tasks, datasets, and populations"},{"categories":["Publications"],"contents":"Title: MEG and fMRI fusion for non-linear estimation of neural and BOLD signal changes\nAuthors: Sergey M Plis, Vince D Calhoun, Michael P Weisend, Tom Eichele, Terran Lane\nYear: 2010\nJournal: Frontiers in neuroinformatics\nVolume: 4\nPages: 114\nPublisher: Frontiers Research Foundation\nDescription:\nThe combined analysis of MEG/EEG and functional MRI measurements can lead to improvement in the description of the dynamical and spatial properties of brain activity. In this paper we empirically demonstrate this improvement using simulated and recorded task related MEG and fMRI activity. Neural activity estimates were derived using a dynamic Bayesian network with continuous real valued parameters by means of a sequential Monte Carlo technique. In synthetic data, we show that MEG and fMRI fusion improves estimation of the indirectly observed neural activity and smooths tracking of the BOLD response. In recordings of task related neural activity the combination of MEG and fMRI produces a result with greater SNR, that confirms the expectation arising from the nature of the experiment. The highly nonlinear model of the BOLD response poses a difficult inference problem for neural activity estimation; computational requirements are also high due to the time and space complexity. We show that joint analysis of the data improves the system's behavior by stabilizing the differential equations system and by requiring fewer computational resources.\nView article\n","permalink":"http://localhost:1313/posts/meg-and-fmri-fusion-for-non-linear-estimation-of-neural-and-bold-signal-changes/","tags":["Paper","Publications"],"title":"MEG and fMRI fusion for non-linear estimation of neural and BOLD signal changes"},{"categories":["Publications"],"contents":"Title: Mesochronal structure learning\nAuthors: Sergey Plis, David Danks, Jianyu Yang\nYear: 2015\nJournal: Uncertainty in artificial intelligence: proceedings of the\u0026hellip; conference. Conference on Uncertainty in Artificial Intelligence\nVolume: 31\nPublisher: NIH Public Access\nDescription:\nStandard time series structure learning algorithms assume that the measurement timescale is approximately the same as the timescale of the underlying (causal) system. In many scientific contexts, however, this assumption is violated: the measurement timescale can be substantially slower than the system timescale (so intermediate time series datapoints will be missing). This assumption violation can lead to significant learning errors. In this paper, we provide a novel learning algorithm to extract system-timescale structure from measurement data that undersample the underlying system. We employ multiple algorithmic optimizations that exploit the problem structure in order to achieve computational tractability. The resulting algorithm is highly reliable at extracting system-timescale structure from undersampled data.\nView article\n","permalink":"http://localhost:1313/posts/block-coordinate-descent-for-sparse-nmf/","tags":["Paper","Publications"],"title":"Mesochronal Structure Learning"},{"categories":["Publications"],"contents":"Title: Mesochronal structure learning\nAuthors: Sergey Plis, David Danks, Jianyu Yang\nYear: 2015\nJournal: Uncertainty in artificial intelligence: proceedings of the\u0026hellip; conference. Conference on Uncertainty in Artificial Intelligence\nVolume: 31\nPublisher: NIH Public Access\nDescription:\nStandard time series structure learning algorithms assume that the measurement timescale is approximately the same as the timescale of the underlying (causal) system. In many scientific contexts, however, this assumption is violated: the measurement timescale can be substantially slower than the system timescale (so intermediate time series datapoints will be missing). This assumption violation can lead to significant learning errors. In this paper, we provide a novel learning algorithm to extract system-timescale structure from measurement data that undersample the underlying system. We employ multiple algorithmic optimizations that exploit the problem structure in order to achieve computational tractability. The resulting algorithm is highly reliable at extracting system-timescale structure from undersampled data.\nView article\n","permalink":"http://localhost:1313/posts/mesochronal-structure-learning/","tags":["Paper","Publications"],"title":"Mesochronal Structure Learning"},{"categories":["Publications"],"contents":"Title: Modeling spatiotemporal covariance for magnetoencephalography or electroencephalography source analysis\nAuthors: Sergey M Plis, JS George, SC Jun, J Paré-Blagoev, DM Ranken, CC Wood, DM Schmidt\nYear: 2007\nJournal: Physical Review E\nVolume: 75\nNumber: 1\nPages: 011928\nPublisher: American Physical Society\nDescription:\nWe propose a new model to approximate spatiotemporal noise covariance for use in neural electromagnetic source analysis, which better captures temporal variability in background activity. As with other existing formalisms, our model employs a Kronecker product of matrices representing temporal and spatial covariance. In our model, spatial components are allowed to have differing temporal covariances. Variability is represented as a series of Kronecker products of spatial component covariances and corresponding temporal covariances. Unlike previous attempts to model covariance through a sum of Kronecker products, our model is designed to have a computationally manageable inverse. Despite increased descriptive power, inversion of the model is fast, making it useful in source analysis. We have explored two versions of the model. One is estimated based on the assumption that spatial components of …\nView article\n","permalink":"http://localhost:1313/posts/modeling-spatiotemporal-covariance-for-magnetoencephalography-or-electroencephalography-source-analysis/","tags":["Paper","Publications"],"title":"Modeling spatiotemporal covariance for magnetoencephalography or electroencephalography source analysis"},{"categories":["Publications"],"contents":"Title: Modeling spatiotemporal noise covariance for MEG EEG source analysis\nAuthors: SM Plis, JS George, SC Jun, J Pare-Blagoev, DM Ranken, DM Schmidt, CC Wood\nYear: 2005\nJournal: arXiv preprint physics/0503063\nDescription:\nWe propose a new model for approximating spatiotemporal noise covariance for use in MEG/EEG source analysis. Our model is an extension of an existing model [1,2] that uses a single Kronecker product of a pair of matrices - temporal and spatial covariance; we employ a series of Kronecker products in order to construct a better approximation of the full covariance. In contrast to the single-pair model that assumes the same temporal structure for all spatial components, the proposed model allows for distinct, independent time courses at each spatial component. This model better describes spatially and temporally correlated background activity. At the same time, inversion of the model is fast which makes it useful in the inverse analysis. We have explored two versions of the model. One is based on orthogonal spatial components of the background. The other, more general model, is based on independent spatial components. Performance of the new and previous models is compared in inverse solutions to a large number of single dipole problems with simulated time courses and background from authentic MEG data.\nView article\n","permalink":"http://localhost:1313/posts/modeling-spatiotemporal-noise-covariance-for-meg-eeg-source-analysis/","tags":["Paper","Publications"],"title":"Modeling spatiotemporal noise covariance for MEG EEG source analysis"},{"categories":["Publications"],"contents":"Title: Modular organization of functional network connectivity in healthy controls and patients with schizophrenia during the resting state\nAuthors: Qingbao Yu, Sergey M Plis, Erik B Erhardt, Elena A Allen, Jing Sui, Kent A Kiehl, Godfrey Pearlson, Vince D Calhoun\nYear: 2012\nJournal: Frontiers in systems neuroscience\nVolume: 5\nPages: 103\nPublisher: Frontiers Research Foundation\nDescription:\nNeuroimaging studies have shown that functional brain networks composed from select regions of interest (ROIs) have a modular community structure. However, the organization of functional network connectivity (FNC), comprising a purely data-driven network built from spatially independent brain components, is not yet clear. The aim of this study is to explore the modular organization of FNC in both healthy controls (HCs) and patients with schizophrenia (SZs). Resting state functional magnetic resonance imaging (R-fMRI) data of HCs and SZs were decomposed into independent components (ICs) by group independent component analysis (ICA). Then weighted brain networks (in which nodes are brain components) were built based on correlations among of ICA time courses. Clustering coefficients and connectivity strength of the networks were computed. A dynamic branch cutting algorithm was used to identify modules of the FNC in HCs and SZs. Results show stronger connectivity strength and higher clustering coefficient in HCs with more and smaller modules in SZs. In addition, HCs and SZs had some different hubs. Our findings demonstrate altered modular architecture of the FNC in schizophrenia and provide insights into abnormal topological organization of intrinsic brain networks in this mental illness.\nView article\n","permalink":"http://localhost:1313/posts/modular-organization-of-functional-network-connectivity-in-healthy-controls-and-patients-with-schizophrenia-during-the-resting-state/","tags":["Paper","Publications"],"title":"Modular organization of functional network connectivity in healthy controls and patients with schizophrenia during the resting state"},{"categories":["Publications"],"contents":"Title: Multi network InfoMax: A pre-training method involving graph convolutional networks\nAuthors: Usman Mahmood, Zening Fu, Vince Calhoun, Sergey Plis\nYear: 2021\nJournal: arXiv preprint arXiv:2111.01276\nDescription:\nDiscovering distinct features and their relations from data can help us uncover valuable knowledge crucial for various tasks, e.g., classification. In neuroimaging, these features could help to understand, classify, and possibly prevent brain disorders. Model introspection of highly performant overparameterized deep learning (DL) models could help find these features and relations. However, to achieve high-performance level DL models require numerous labeled training samples () rarely available in many fields. This paper presents a pre-training method involving graph convolutional/neural networks (GCNs/GNNs), based on maximizing mutual information between two high-level embeddings of an input sample. Many of the recently proposed pre-training methods pre-train one of many possible networks of an architecture. Since almost every DL model is an ensemble of multiple networks, we take our high-level embeddings from two different networks of a model \u0026ndash;a convolutional and a graph network\u0026ndash;. The learned high-level graph latent representations help increase performance for downstream graph classification tasks and bypass the need for a high number of labeled data samples. We apply our method to a neuroimaging dataset for classifying subjects into healthy control (HC) and schizophrenia (SZ) groups. Our experiments show that the pre-trained model significantly outperforms the non-pre-trained model and requires less data for similar performance.\nView article\n","permalink":"http://localhost:1313/posts/multi-network-infomax-a-pre-training-method-involving-graph-convolutional-networks/","tags":["Paper","Publications"],"title":"Multi network InfoMax - A pre-training method involving graph convolutional networks"},{"categories":["Publications"],"contents":"Title: Multidataset independent subspace analysis\nAuthors: Rogers F Silva, SM Plis, T Adalı, VD Calhoun\nYear: 2014\nJournal: Proc OHBM\nPages: 3506\nDescription:\nMultidataset Independent Subspace Analysis Page 1 Multidataset Independent Subspace Analysis Rogers F. Silva, Ph.D. Postdoctoral Fellow The Mind Research Network Data Scientist Datalytic Solutions with Sergey M. Plis, Ph.D. (MRN) Tulay Adali, Ph.D. (UMBC) Marios S. Pattichis, Ph.D. (UNM) Vince D. Calhoun, Ph.D. (MRN/UNM) Jun/30/2017 2017 Deep Learning Summer School University of Montreal Page 2 Page 3 Page 4 Page 5 Page 6 Page 7 Page 8 Multidataset Multidimensional Problems • A Hierarchy of Blind Source Separation Models [Silva et al., 2016] Page 9 h𝑘 y𝑘 = − 𝑦 𝑘 2 𝜎 𝑘 2 − 1 2 logdet𝜎 𝑘 2 𝐱 𝐖 𝐏𝑘 𝐲 = 𝐖𝐱 𝐽 𝐖 = 𝐾𝐿 𝑝(𝐲), 𝑝𝑘(𝐲𝑘) 𝐾 𝑘 , 𝐽 𝐖 = − log 𝜎𝑖 𝐶=𝐾 𝑖 − 𝔼 h𝑘 y𝑘 𝐾 𝑘 , Multidataset Multidimensional Problems • A Hierarchy of Blind Source Separation Models [Silva et al., 2016] SDU Single Dataset (SD) Page 10 𝐽 𝐖 = 𝐾𝐿 𝑝(𝐲), 𝑝𝑘(𝐲𝑘) 𝐾 𝑘 , 𝐽 𝐖 = − log 𝜎𝑚𝑖 𝐶𝑚=𝐾 𝑖 𝑀 𝑚 − 𝔼 h𝑘 𝐲𝑘 …\nView article\n","permalink":"http://localhost:1313/posts/multidataset-independent-subspace-analysis/","tags":["Paper","Publications"],"title":"Multidataset independent subspace analysis"},{"categories":["Publications"],"contents":"Title: Multidataset independent subspace analysis with application to multimodal fusion\nAuthors: Rogers F Silva, Sergey M Plis, Tülay Adalı, Marios S Pattichis, Vince D Calhoun\nYear: 2020\nJournal: IEEE Transactions on Image Processing\nVolume: 30\nPages: 588-602\nPublisher: IEEE\nDescription:\nUnsupervised latent variable models-blind source separation (BSS) especially-enjoy a strong reputation for their interpretability. But they seldom combine the rich diversity of information available in multiple datasets, even though multidatasets yield insightful joint solutions otherwise unavailable in isolation. We present a direct, principled approach to multidataset combination that takes advantage of multidimensional subspace structures. In turn, we extend BSS models to capture the underlying modes of shared and unique variability across and within datasets. Our approach leverages joint information from heterogeneous datasets in a flexible and synergistic fashion. We call this method multidataset independent subspace analysis (MISA). Methodological innovations exploiting the Kotz distribution for subspace modeling, in conjunction with a novel combinatorial optimization for evasion of local minima, enable …\nView article\n","permalink":"http://localhost:1313/posts/multidataset-independent-subspace-analysis-with-application-to-multimodal-fusion/","tags":["Paper","Publications"],"title":"Multidataset independent subspace analysis with application to multimodal fusion"},{"categories":["Publications"],"contents":"Title: Multiplicative updates For Non-Negative Kernel SVM\nAuthors: Vamsi K Potluru, Sergey M Plis, Morten Morup, Vince D Calhoun, Terran Lane\nYear: 2009\nJournal: arXiv preprint arXiv:0902.4228\nDescription:\nWe present multiplicative updates for solving hard and soft margin support vector machines (SVM) with non-negative kernels. They follow as a natural extension of the updates for non-negative matrix factorization. No additional param- eter setting, such as choosing learning, rate is required. Ex- periments demonstrate rapid convergence to good classifiers. We analyze the rates of asymptotic convergence of the up- dates and establish tight bounds. We test the performance on several datasets using various non-negative kernels and report equivalent generalization errors to that of a standard SVM.\nView article\n","permalink":"http://localhost:1313/posts/multiplicative-updates-for-non-negative-kernel-svm/","tags":["Paper","Publications"],"title":"Multiplicative updates For Non-Negative Kernel SVM"},{"categories":["Publications"],"contents":"Title: Neurocrypt: Machine learning over encrypted distributed neuroimaging data\nAuthors: Nipuna Senanayake, Robert Podschwadt, Daniel Takabi, Vince D Calhoun, Sergey M Plis\nYear: 2022\nJournal: Neuroinformatics\nVolume: 20\nNumber: 1\nPages: 91-108\nPublisher: Springer US\nDescription:\nThe field of neuroimaging can greatly benefit from building machine learning models to detect and predict diseases, and discover novel biomarkers, but much of the data collected at various organizations and research centers is unable to be shared due to privacy or regulatory concerns (especially for clinical data or rare disorders). In addition, aggregating data across multiple large studies results in a huge amount of duplicated technical debt and the resources required can be challenging or impossible for an individual site to build. Training on the data distributed across organizations can result in models that generalize much better than models trained on data from any of organizations alone. While there are approaches for decentralized sharing, these often do not provide the highest possible guarantees of sample privacy that only cryptography can provide. In addition, such approaches are often focused on …\nView article\n","permalink":"http://localhost:1313/posts/neurocrypt-machine-learning-over-encrypted-distributed-neuroimaging-data/","tags":["Paper","Publications"],"title":"Neurocrypt - Machine learning over encrypted distributed neuroimaging data"},{"categories":["Publications"],"contents":"Title: Patterns of co-occurring gray matter concentration loss across the Huntington disease prodrome\nAuthors: Jennifer Ashley Ciarochi, Vince D Calhoun, Spencer Lourens, Jeffrey D Long, Hans J Johnson, H Jeremy Bockholt, Jingyu Liu, Sergey M Plis, Jane S Paulsen, Jessica A Turner, PREDICT-HD Investigators, Coordinators of the Huntington Study Group\nYear: 2016\nJournal: Frontiers in neurology\nVolume: 7\nPages: 147\nPublisher: Frontiers Media SA\nDescription:\nHuntington disease is caused by an abnormally expanded CAG trinucleotide repeat in the HTT gene. Age and CAG-expansion number are related to age at diagnosis, and can be used to index disease progression. However, observed onset-age variability suggests that other factors also modulate progression. Indexing prodromal (pre-diagnosis) progression may highlight therapeutic targets by isolating the earliest-affected factors. We present the largest prodromal Huntington disease application of the univariate method Voxel-based Morphometry, and the first application of the multivariate method Source-based Morphometry, to respectively compare gray matter concentration and capture co-occurring gray matter concentration patterns in control and prodromal participants. Using structural MRI data from 1050 (831 prodromal, 219 control) participants, we characterize control-prodromal, whole-brain gray matter concentration differences at various prodromal stages. Our results provide evidence for: (1) Regional co-occurrence and differential patterns of decline across the prodrome, with parietal and occipital differences commonly co-occurring, and frontal and temporal differences being relatively independent from one another, (2) Fronto-striatal circuits being among the earliest and most consistently affected in the prodrome (3) Delayed degradation in some movement-related regions, with increasing subcortical and occipital differences with later progression, (4) An overall superior-to-inferior gradient of gray matter concentration reduction in frontal, parietal, and temporal lobes, (5) The appropriateness of Source-based Morphometry for studying …\nView article\n","permalink":"http://localhost:1313/posts/patterns-of-co-occurring-gray-matter-concentration-loss-across-the-huntington-disease-prodrome/","tags":["Paper","Publications"],"title":"Patterns of co-occurring gray matter concentration loss across the Huntington disease prodrome"},{"categories":["Publications"],"contents":"Title: Peering Beyond the Gradient Veil with Distributed Auto Differentiation\nAuthors: Bradley T Baker, Aashis Khanal, Vince D Calhoun, Barak Pearlmutter, Sergey M Plis\nYear: 2021\nJournal: arXiv e-prints\nPages: arXiv: 2102.09631\nDescription:\nAlthough distributed machine learning has opened up many new and exciting research frontiers, fragmentation of models and data across different machines, nodes, and sites still results in considerable communication overhead, impeding reliable training in real-world contexts. The focus on gradients as the primary shared statistic during training has spawned a number of intuitive algorithms for distributed deep learning; however, gradient-centric training of large deep neural networks (DNNs) tends to be communication-heavy, often requiring additional adaptations such as sparsity constraints, compression, quantization, and more, to curtail bandwidth. We introduce an innovative, communication-friendly approach for training distributed DNNs, which capitalizes on the outer-product structure of the gradient as revealed by the mechanics of auto-differentiation. The exposed structure of the gradient evokes a new class …\nView article\n","permalink":"http://localhost:1313/posts/peering-beyond-the-gradient-veil-with-distributed-auto-differentiation/","tags":["Paper","Publications"],"title":"Peering Beyond the Gradient Veil with Distributed Auto Differentiation"},{"categories":["Publications"],"contents":"Title: Privacy-preserving quality control of neuroimaging datasets in federated environment\nAuthors: Debbrata K Saha, VD Calhoun, Y Du, Z Fu, Sandeep R Panta, S Kwon, AD Sarwate, SM Plis\nYear: 2021\nJournal: bioRxiv\nPages: 826974\nPublisher: Cold Spring Harbor Laboratory\nDescription:\nPrivacy concerns for rare disease data, institutional or IRB policies, access to local computational or storage resources or download capabilities are among the reasons that may preclude analyses that pool data to a single site. A growing number of multi-site projects and consortia were formed to function in the federated environment to conduct productive research under constraints of this kind. In this scenario, a quality control tool that visualizes decentralized data in its entirety via global aggregation of local computations is especially important, as it would allow the screening of samples that cannot be jointly evaluated otherwise. To solve this issue, we present two algorithms: decentralized data stochastic neighbor embedding, dSNE, and its differentially private counterpart, DP-dSNE. We leverage publicly available datasets to simultaneously map data samples located at different sites according to their similarities. Even though the data never leaves the individual sites, dSNE does not provide any formal privacy guarantees. To overcome that, we rely on differential privacy: a formal mathematical guarantee that protects individuals from being identified as contributors to a dataset. We implement DP-dSNE with AdaCliP, a method recently proposed to add less noise to the gradients per iteration. We introduce metrics for measuring the embedding quality and validate our algorithms on these metrics against their centralized counterpart on two toy datasets. Our validation on six multi-site neuroimaging datasets shows promising results for the quality control tasks of visualization and outlier detection, highlighting the potential of our private, decentralized …\nView article\n","permalink":"http://localhost:1313/posts/privacy-preserving-quality-control-of-neuroimaging-datasets-in-federated-environment/","tags":["Paper","Publications"],"title":"Privacy-preserving quality control of neuroimaging datasets in federated environment"},{"categories":["Publications"],"contents":"Title: Privacy‐preserving quality control of neuroimaging datasets in federated environments\nAuthors: Debbrata K Saha, Vince D Calhoun, Yuhui Du, Zening Fu, Soo Min Kwon, Anand D Sarwate, Sandeep R Panta, Sergey M Plis\nYear: 2022\nJournal: Human Brain Mapping\nVolume: 43\nNumber: 7\nPages: 2289-2310\nPublisher: John Wiley \u0026amp; Sons, Inc.\nDescription:\nPrivacy concerns for rare disease data, institutional or IRB policies, access to local computational or storage resources or download capabilities are among the reasons that may preclude analyses that pool data to a single site. A growing number of multisite projects and consortia were formed to function in the federated environment to conduct productive research under constraints of this kind. In this scenario, a quality control tool that visualizes decentralized data in its entirety via global aggregation of local computations is especially important, as it would allow the screening of samples that cannot be jointly evaluated otherwise. To solve this issue, we present two algorithms: decentralized data stochastic neighbor embedding, dSNE, and its differentially private counterpart, DP‐dSNE. We leverage publicly available datasets to simultaneously map data samples located at different sites according to their similarities …\nView article\n","permalink":"http://localhost:1313/posts/privacy%CE%B3%C3%A7%C3%A9preserving-quality-control-of-neuroimaging-datasets-in-federated-environments/","tags":["Paper","Publications"],"title":"Privacy‐preserving quality control of neuroimaging datasets in federated environments"},{"categories":["Publications"],"contents":"Title: Probabilistic forward model for electroencephalography source analysis\nAuthors: Sergey M Plis, John S George, Sung C Jun, Doug M Ranken, Petr L Volegov, David M Schmidt\nYear: 2007\nJournal: Physics in Medicine \u0026amp; Biology\nVolume: 52\nNumber: 17\nPages: 5309\nPublisher: IOP Publishing\nDescription:\nSource localization by electroencephalography (EEG) requires an accurate model of head geometry and tissue conductivity. The estimation of source time courses from EEG or from EEG in conjunction with magnetoencephalography (MEG) requires a forward model consistent with true activity for the best outcome. Although MRI provides an excellent description of soft tissue anatomy, a high resolution model of the skull (the dominant resistive component of the head) requires CT, which is not justified for routine physiological studies. Although a number of techniques have been employed to estimate tissue conductivity, no present techniques provide the noninvasive 3D tomographic mapping of conductivity that would be desirable. We introduce a formalism for probabilistic forward modeling that allows the propagation of uncertainties in model parameters into possible errors in source localization. We consider …\nView article\n","permalink":"http://localhost:1313/posts/probabilistic-forward-model-for-electroencephalography-source-analysis/","tags":["Paper","Publications"],"title":"Probabilistic forward model for electroencephalography source analysis"},{"categories":["Publications"],"contents":"Title: Quantitative EEG biomarkers for mild traumatic brain injury\nAuthors: Jeffrey D Lewine, Sergey Plis, Alvaro Ulloa, Christopher Williams, Mark Spitz, John Foley, Kim Paulson, John Davis, Nitin Bangera, Travis Snyder, Lindell Weaver\nYear: 2019\nJournal: Journal of Clinical Neurophysiology\nVolume: 36\nNumber: 4\nPages: 298-305\nPublisher: LWW\nDescription:\nPurpose:The development of objective biomarkers for mild traumatic brain injury (mTBI) in the chronic period is an important clinical and research goal. Head trauma is known to affect the mechanisms that support the electrophysiological processing of information within and between brain regions, so methods like quantitative EEG may provide viable indices of brain dysfunction associated with even mTBI.Methods:Resting-state, eyes-closed EEG data were obtained from 71 individuals with military-related mTBI and 82 normal comparison subjects without traumatic brain injury. All mTBI subjects were in the chronic period of injury (\u0026gt; 5 months since the time of injury). Quantitative metrics included absolute and relative power in delta, theta, alpha, beta, high beta, and gamma bands, plus a measure of interhemispheric coherence in each band. Data were analyzed using univariate and multivariate methods, the latter …\nView article\n","permalink":"http://localhost:1313/posts/quantitative-eeg-biomarkers-for-mild-traumatic-brain-injury/","tags":["Paper","Publications"],"title":"Quantitative EEG biomarkers for mild traumatic brain injury"},{"categories":["Publications"],"contents":"Title: Relationships between alpha oscillations during speech preparation and the listener N400 ERP to the produced speech\nAuthors: David A Bridwell, Sarah Henderson, Marieke Sorge, Sergey Plis, Vince D Calhoun\nYear: 2018\nJournal: Scientific Reports\nVolume: 8\nNumber: 1\nPages: 1-10\nPublisher: Nature Publishing Group\nDescription:\nWhile previous studies separately demonstrate EEG spectral modulations during speech preparation and ERP responses to the listened speech, it is unclear whether these responses are related on a trial-by-trial basis between a speaker and listener. In order to determine whether these responses are related in real-time, Electroencephalography (EEG) responses were measured simultaneously within a speaker and listener using a 24 electrode Mobile EEG system (18 participants; 9 pairs) during a sentence completion task. Each trial consisted of a sentence prompt with an incomplete ending (e.g. “I took my dog for a ____”). The speaker was instructed to fill in the ending with something expected (e.g. “walk”) (40 trials) or unexpected (e.g. “drink”) (40 trials). The other participant listened to the speaker throughout the block. We found that lower alpha band activity was reduced when individuals prepared unexpected …\nView article\n","permalink":"http://localhost:1313/posts/relationships-between-alpha-oscillations-during-speech-preparation-and-the-listener-n400-erp-to-the-produced-speech/","tags":["Paper","Publications"],"title":"Relationships between alpha oscillations during speech preparation and the listener N400 ERP to the produced speech"},{"categories":["Publications"],"contents":"Title: Restricted Boltzmann machines for neuroimaging: an application in identifying intrinsic networks\nAuthors: R Devon Hjelm, Vince D Calhoun, Ruslan Salakhutdinov, Elena A Allen, Tulay Adali, Sergey M Plis\nYear: 2014\nJournal: NeuroImage\nVolume: 96\nPages: 245-260\nPublisher: Academic Press\nDescription:\nMatrix factorization models are the current dominant approach for resolving meaningful data-driven features in neuroimaging data. Among them, independent component analysis (ICA) is arguably the most widely used for identifying functional networks, and its success has led to a number of versatile extensions to group and multimodal data. However there are indications that ICA may have reached a limit in flexibility and representational capacity, as the majority of such extensions are case-driven, custom-made solutions that are still contained within the class of mixture models. In this work, we seek out a principled and naturally extensible approach and consider a probabilistic model known as a restricted Boltzmann machine (RBM). An RBM separates linear factors from functional brain imaging data by fitting a probability distribution model to the data. Importantly, the solution can be used as a building block for …\nView article\n","permalink":"http://localhost:1313/posts/restricted-boltzmann-machines-for-neuroimaging-an-application-in-identifying-intrinsic-networks/","tags":["Paper","Publications"],"title":"Restricted Boltzmann machines for neuroimaging - an application in identifying intrinsic networks"},{"categories":["Publications"],"contents":"Title: Run, skeleton, run: skeletal model in a physics-based simulation\nAuthors: Mikhail Pavlov, Sergey Kolesnikov, Sergey M Plis\nYear: 2017\nJournal: arXiv preprint arXiv:1711.06922\nDescription:\nIn this paper, we present our approach to solve a physics-based reinforcement learning challenge \u0026quot;Learning to Run\u0026quot; with objective to train physiologically-based human model to navigate a complex obstacle course as quickly as possible. The environment is computationally expensive, has a high-dimensional continuous action space and is stochastic. We benchmark state of the art policy-gradient methods and test several improvements, such as layer normalization, parameter noise, action and state reflecting, to stabilize training and improve its sample-efficiency. We found that the Deep Deterministic Policy Gradient method is the most efficient method for this environment and the improvements we have introduced help to stabilize training. Learned models are able to generalize to new physical scenarios, e.g. different obstacle courses.\nView article\n","permalink":"http://localhost:1313/posts/run-skeleton-run-skeletal-model-in-a-physics-based-simulation/","tags":["Paper","Publications"],"title":"Run, skeleton, run - skeletal model in a physics-based simulation"},{"categories":["Publications"],"contents":"Title: Scalable learning of large networks\nAuthors: Sushmita Roy, Sergey Plis, Margaret Werner-Washburne, Terran Lane\nYear: 2009\nJournal: IET systems biology\nVolume: 3\nNumber: 5\nPages: 404-413\nPublisher: IET Digital Library\nDescription:\nCellular networks inferred from condition-specific microarray data can capture the functional rewiring of cells in response to different environmental conditions. Unfortunately, many algorithms for inferring cellular networks do not scale to whole-genome data with thousands of variables. We propose a novel approach for scalable learning of large networks: cluster and infer networks (CIN). CIN learns network structures in two steps: (a) partition variables into smaller clusters, and (b) learn networks per cluster. We optionally revisit the cluster assignment of variables with poor neighbourhoods. Results on networks with known topologies suggest that CIN has substantial speed benefits, without substantial performance loss. We applied our approach to microarray compendia of glucose-starved yeast cells. The inferred networks had significantly higher number of subgraphs representing meaningful biological …\nView article\n","permalink":"http://localhost:1313/posts/scalable-learning-of-large-networks/","tags":["Paper","Publications"],"title":"Scalable learning of large networks"},{"categories":["Publications"],"contents":"Title: Self-Supervised Mental Disorder Classifiers via Time Reversal\nAuthors: Zafar Iqbal, Usman Mehmood, Zening Fu, Sergey Plis\nYear: 2022\nJournal: arXiv preprint arXiv:2211.16398\nDescription:\nData scarcity is a notable problem, especially in the medical domain, due to patient data laws. Therefore, efficient Pre-Training techniques could help in combating this problem. In this paper, we demonstrate that a model trained on the time direction of functional neuro-imaging data could help in any downstream task, for example, classifying diseases from healthy controls in fMRI data. We train a Deep Neural Network on Independent components derived from fMRI data using the Independent component analysis (ICA) technique. It learns time direction in the ICA-based data. This pre-trained model is further trained to classify brain disorders in different datasets. Through various experiments, we have shown that learning time direction helps a model learn some causal relation in fMRI data that helps in faster convergence, and consequently, the model generalizes well in downstream classification tasks even with fewer data records.\nView article\n","permalink":"http://localhost:1313/posts/self-supervised-mental-disorder-classifiers-via-time-reversal/","tags":["Paper","Publications"],"title":"Self-Supervised Mental Disorder Classifiers via Time Reversal"},{"categories":["Publications"],"contents":"Title: Spatio-temporal Dynamics of Intrinsic Networks in Functional Magnetic Imaging Data Using Recurrent Neural Networks\nAuthors: R Devon Hjelm, Eswar Damaraju, Kyunghyun Cho, Helmut Laufs, Sergey M Plis, Vince Calhoun\nYear: 2016\nJournal: arXiv e-prints\nPages: arXiv: 1611.00864\nDescription:\nWe introduce a novel recurrent neural network (RNN) approach to account for temporal dynamics and dependencies in brain networks observed via functional magnetic resonance imaging (fMRI). Our approach directly parameterizes temporal dynamics through recurrent connections, which can be used to formulate blind source separation with a conditional (rather than marginal) independence assumption, which we call RNN-ICA. This formulation enables us to visualize the temporal dynamics of both first order (activity) and second order (directed connectivity) information in brain networks that are widely studied in a static sense, but not well-characterized dynamically. RNN-ICA predicts dynamics directly from the recurrent states of the RNN in both task and resting state fMRI. Our results show both task-related and group-differentiating directed connectivity.\nView article\n","permalink":"http://localhost:1313/posts/spatio-temporal-dynamics-of-intrinsic-networks-in-functional-magnetic-imaging-data-using-recurrent-neural-networks/","tags":["Paper","Publications"],"title":"Spatio-temporal Dynamics of Intrinsic Networks in Functional Magnetic Imaging Data Using Recurrent Neural Networks"},{"categories":["Publications"],"contents":"Title: Spatiotemporal Bayesian inference dipole analysis for MEG neuroimaging data\nAuthors: Sung C Jun, John S George, Juliana Paré-Blagoev, Sergey M Plis, Doug M Ranken, David M Schmidt, CC Wood\nYear: 2005\nJournal: NeuroImage\nVolume: 28\nNumber: 1\nPages: 84-98\nPublisher: Academic Press\nDescription:\nRecently, we described a Bayesian inference approach to the MEG/EEG inverse problem that used numerical techniques to estimate the full posterior probability distributions of likely solutions upon which all inferences were based [Schmidt, D.M., George, J.S., Wood, C.C., 1999. Bayesian inference applied to the electromagnetic inverse problem. Human Brain Mapping 7, 195; Schmidt, D.M., George, J.S., Ranken, D.M., Wood, C.C., 2001. Spatial-temporal bayesian inference for MEG/EEG. In: Nenonen, J., Ilmoniemi, R. J., Katila, T. (Eds.), Biomag 2000: 12th International Conference on Biomagnetism. Espoo, Norway, p. 671]. Schmidt et al. (1999) focused on the analysis of data at a single point in time employing an extended region source model. They subsequently extended their work to a spatiotemporal Bayesian inference analysis of the full spatiotemporal MEG/EEG data set. Here, we formulate spatiotemporal …\nView article\n","permalink":"http://localhost:1313/posts/spatiotemporal-bayesian-inference-dipole-analysis-for-meg-neuroimaging-data/","tags":["Paper","Publications"],"title":"Spatiotemporal Bayesian inference dipole analysis for MEG neuroimaging data"},{"categories":["Publications"],"contents":"Title: Spatiotemporal noise covariance estimation from limited empirical magnetoencephalographic data\nAuthors: Sung C Jun, Sergey M Plis, Doug M Ranken, David M Schmidt\nYear: 2006\nJournal: Physics in Medicine \u0026amp; Biology\nVolume: 51\nNumber: 21\nPages: 5549\nPublisher: IOP Publishing\nDescription:\nThe performance of parametric magnetoencephalography (MEG) and electroencephalography (EEG) source localization approaches can be degraded by the use of poor background noise covariance estimates. In general, estimation of the noise covariance for spatiotemporal analysis is difficult mainly due to the limited noise information available. Furthermore, its estimation requires a large amount of storage and a one-time but very large (and sometimes intractable) calculation or its inverse. To overcome these difficulties, noise covariance models consisting of one pair or a sum of multi-pairs of Kronecker products of spatial covariance and temporal covariance have been proposed. However, these approaches cannot be applied when the noise information is very limited, ie, the amount of noise information is less than the degrees of freedom of the noise covariance models. A common example of this is when only …\nView article\n","permalink":"http://localhost:1313/posts/spatiotemporal-noise-covariance-estimation-from-limited-empirical-magnetoencephalographic-data/","tags":["Paper","Publications"],"title":"Spatiotemporal noise covariance estimation from limited empirical magnetoencephalographic data"},{"categories":["Publications"],"contents":"Title: Statelets: high dimensional predominant shapes in dynamic functional network connectivity\nAuthors: Md Abdur Rahaman, Eswar Damaraju, Debbrata Kumar Saha, Sergey M Plis, Vince D Calhoun\nYear: 2020\nJournal: bioRxiv\nPublisher: Cold Spring Harbor Laboratory\nDescription:\nDynamic functional network connectivity (dFNC) analysis is a widely used approach for capturing brain activation patterns, connectivity states, and network organization. However, a typical sliding window plus clustering (SWC) approaches for analyzing dFNC continuously models the system through a fixed set of connectivity patterns or states. It assumes these patterns are span throughout the brain, but in practice, they are more spatially constrained and temporally short-lived. Thus, SWC is not designed to capture transient dynamic changes nor heterogeneity across subjects/time. Here, we adapt time series motifs to model the temporal dynamics of functional connectivity. We propose a state-space data mining approach that combines a probabilistic pattern summarization framework called ‘Statelets’ — a subset of high dimensional state-shape prototypes capturing the dynamics. We handle scale differences using the earth mover distance and utilize kernel density estimation to build a probability density profile for local motifs. We apply the framework to study dFNC collected from patients with schizophrenia (SZ) and healthy control (HC). Results demonstrate SZ subjects exhibit reduced modularity in their brain network organization relative to HC. These statelets in the HC group show more recurrence across the dFNC time-course compared to the SZ. An analysis of the consistency of the connections across time reveals significant differences within visual, sensorimotor, and default mode regions where HC subjects show higher consistency than SZ. The introduced statelet-approach also enables the handling of dynamic information in cross-modal …\nView article\n","permalink":"http://localhost:1313/posts/statelets-high-dimensional-predominant-shapes-in-dynamic-functional-network-connectivity/","tags":["Paper","Publications"],"title":"Statelets - high dimensional predominant shapes in dynamic functional network connectivity"},{"categories":["Publications"],"contents":"Title: Task-specific feature extraction and classification of fMRI volumes using a deep neural network initialized with a deep belief network: Evaluation using sensorimotor tasks\nAuthors: Hojin Jang, Sergey M Plis, Vince D Calhoun, Jong-Hwan Lee\nYear: 2017\nJournal: NeuroImage\nVolume: 145\nPages: 314-328\nPublisher: Academic Press\nDescription:\nFeedforward deep neural networks (DNNs), artificial neural networks with multiple hidden layers, have recently demonstrated a record-breaking performance in multiple areas of applications in computer vision and speech processing. Following the success, DNNs have been applied to neuroimaging modalities including functional/structural magnetic resonance imaging (MRI) and positron-emission tomography data. However, no study has explicitly applied DNNs to 3D whole-brain fMRI volumes and thereby extracted hidden volumetric representations of fMRI that are discriminative for a task performed as the fMRI volume was acquired. Our study applied fully connected feedforward DNN to fMRI volumes collected in four sensorimotor tasks (i.e., left-hand clenching, right-hand clenching, auditory attention, and visual stimulus) undertaken by 12 healthy participants. Using a leave-one-subject-out cross-validation …\nView article\n","permalink":"http://localhost:1313/posts/task-specific-feature-extraction-and-classification-of-fmri-volumes-using-a-deep-neural-network-initialized-with-a-deep-belief-network-evaluation-using-sensorimotor-tasks/","tags":["Paper","Publications"],"title":"Task-specific feature extraction and classification of fMRI volumes using a deep neural network initialized with a deep belief network - Evaluation using sensorimotor tasks"},{"categories":["Publications"],"contents":"Title: Tasting the cake: evaluating self-supervised generalization on out-of-distribution multimodal MRI data\nAuthors: Alex Fedorov, Eloy Geenjaar, Lei Wu, Thomas P DeRamus, Vince D Calhoun, Sergey M Plis\nYear: 2021\nJournal: arXiv preprint arXiv:2103.15914\nDescription:\nSelf-supervised learning has enabled significant improvements on natural image benchmarks. However, there is less work in the medical imaging domain in this area. The optimal models have not yet been determined among the various options. Moreover, little work has evaluated the current applicability limits of novel self-supervised methods. In this paper, we evaluate a range of current contrastive self-supervised methods on out-of-distribution generalization in order to evaluate their applicability to medical imaging. We show that self-supervised models are not as robust as expected based on their results in natural imaging benchmarks and can be outperformed by supervised learning with dropout. We also show that this behavior can be countered with extensive augmentation. Our results highlight the need for out-of-distribution generalization standards and benchmarks to adopt the self-supervised methods in the medical imaging community.\nView article\n","permalink":"http://localhost:1313/posts/tasting-the-cake-evaluating-self-supervised-generalization-on-out-of-distribution-multimodal-mri-data/","tags":["Paper","Publications"],"title":"Tasting the cake - evaluating self-supervised generalization on out-of-distribution multimodal MRI data"},{"categories":["Publications"],"contents":"Title: The influence of visuospatial attention on unattended auditory 40 Hz responses\nAuthors: Cullen Roth, Cota Navin Gupta, Sergey M Plis, Eswar Damaraju, Siddharth Khullar, Vince D Calhoun, David A Bridwell\nYear: 2013\nJournal: Frontiers in human neuroscience\nVolume: 7\nPages: 370\nPublisher: Frontiers Media SA\nDescription:\nInformation must integrate from multiple brain areas in healthy cognition and perception. The present study examined the extent to which cortical responses within one sensory modality are modulated by a complex task conducted within another sensory modality. Electroencephalographic (EEG) responses were measured to a 40 Hz auditory stimulus while individuals attended to modulations in the amplitude of the 40 Hz stimulus, and as a function of the intensity of the popular computer game Tetris. The steady-state response to the 40 Hz stimulus was isolated by Fourier analysis of the EEG. The response at the stimulus frequency was normalized by the response within the surrounding frequencies, generating the signal-to-noise ratio (SNR). Seven out of 8 individuals demonstrate a monotonic increase in the log SNR of the 40 Hz responses going from the difficult visuospatial task to the easy visuospatial task to attending to the auditory stimuli. This pattern is represented statistically by a one-way ANOVA, indicating significant differences in log SNR across the three tasks. The sensitivity of 40 Hz auditory responses to the visuospatial load was further demonstrated by a significant correlation between log SNR and the difficulty (i.e. speed) of the Tetris task. Thus, the results demonstrate that 40 Hz auditory cortical responses are influenced by an individual’s goal-directed attention to the stimulus, and by the degree of difficulty of a complex visuospatial task.\nView article\n","permalink":"http://localhost:1313/posts/the-influence-of-visuospatial-attention-on-unattended-auditory-40-hz-responses/","tags":["Paper","Publications"],"title":"The influence of visuospatial attention on unattended auditory 40 Hz responses"},{"categories":["Publications"],"contents":"Title: Through the looking glass: Deep interpretable dynamic directed connectivity in resting fMRI\nAuthors: Usman Mahmood, Zening Fu, Satrajit Ghosh, Vince Calhoun, Sergey Plis\nYear: 2022\nJournal: NeuroImage\nVolume: 264\nPages: 119737\nPublisher: Academic Press\nDescription:\nBrain network interactions are commonly assessed via functional (network) connectivity, captured as an undirected matrix of Pearson correlation coefficients. Functional connectivity can represent static and dynamic relations, but often these are modeled using a fixed choice for the data window Alternatively, deep learning models may flexibly learn various representations from the same data based on the model architecture and the training task. However, the representations produced by deep learning models are often difficult to interpret and require additional posthoc methods, e.g., saliency maps. In this work, we integrate the strengths of deep learning and functional connectivity methods while also mitigating their weaknesses. With interpretability in mind, we present a deep learning architecture that exposes a directed graph layer that represents what the model has learned about relevant brain connectivity. A …\nView article\n","permalink":"http://localhost:1313/posts/through-the-looking-glass-deep-interpretable-dynamic-directed-connectivity-in-resting-fmri/","tags":["Paper","Publications"],"title":"Through the looking glass - Deep interpretable dynamic directed connectivity in resting fMRI"},{"categories":["Publications"],"contents":"Authors : Elena A Allen, Eswar Damaraju, Sergey M Plis, Erik B Erhardt, Tom Eichele, Vince D Calhoun\nPublication date : 2014/3/1\nJournal : Cerebral cortex\nVolume : 24\nIssue : 3\nPages : 663-676\nPublisher : Oxford University Press\nDescription\nSpontaneous fluctuations are a hallmark of recordings of neural signals, emergent over time scales spanning milliseconds and tens of minutes. However, investigations of intrinsic brain organization based on resting-state functional magnetic resonance imaging have largely not taken into account the presence and potential of temporal variability, as most current approaches to examine functional connectivity (FC) implicitly assume that relationships are constant throughout the length of the recording. In this work, we describe an approach to assess whole-brain FC dynamics based on spatial independent component analysis, sliding time window correlation, and k-means clustering of windowed correlation matrices. The method is applied to resting-state data from a large sample (n = 405) of young adults. Our analysis of FC variability highlights particularly flexible connections between regions in lateral parietal …\nView article\n","permalink":"http://localhost:1313/posts/tracking-whole-brain-connectivity-dynamics-in-the-resting-state/","tags":["Paper","Publications"],"title":"Tracking whole-brain connectivity dynamics in the resting state"},{"categories":["Publications"],"contents":"Title: Transfer learning of fMRI dynamics\nAuthors: Usman Mahmood, Md Mahfuzur Rahman, Alex Fedorov, Zening Fu, Sergey Plis\nYear: 2019\nJournal: arXiv preprint arXiv:1911.06813\nDescription:\nAs a mental disorder progresses, it may affect brain structure, but brain function expressed in brain dynamics is affected much earlier. Capturing the moment when brain dynamics express the disorder is crucial for early diagnosis. The traditional approach to this problem via training classifiers either proceeds from handcrafted features or requires large datasets to combat the problem when a high dimensional fMRI volume only has a single label that carries learning signal. Large datasets may not be available for a study of each disorder, or rare disorder types or sub-populations may not warrant for them. In this paper, we demonstrate a self-supervised pre-training method that enables us to pre-train directly on fMRI dynamics of healthy control subjects and transfer the learning to much smaller datasets of schizophrenia. Not only we enable classification of disorder directly based on fMRI dynamics in small data but also significantly speed up the learning when possible. This is encouraging evidence of informative transfer learning across datasets and diagnostic categories.\nView article\n","permalink":"http://localhost:1313/posts/transfer-learning-of-fmri-dynamics/","tags":["Paper","Publications"],"title":"Transfer learning of fMRI dynamics"},{"categories":["Publications"],"contents":"Title: Variational Autoencoders for Feature Detection of Magnetic Resonance Imaging Data\nAuthors: R Devon Hjelm, Sergey M Plis, Vince C Calhoun\nYear: 2016\nJournal: arXiv e-prints\nPages: arXiv: 1603.06624\nDescription:\nIndependent component analysis (ICA), as an approach to the blind source-separation (BSS) problem, has become the de-facto standard in many medical imaging settings. Despite successes and a large ongoing research effort, the limitation of ICA to square linear transformations have not been overcome, so that general INFOMAX is still far from being realized. As an alternative, we present feature analysis in medical imaging as a problem solved by Helmholtz machines, which include dimensionality reduction and reconstruction of the raw data under the same objective, and which recently have overcome major difficulties in inference and learning with deep and nonlinear configurations. We demonstrate one approach to training Helmholtz machines, variational auto-encoders (VAE), as a viable approach toward feature extraction with magnetic resonance imaging (MRI) data.\nView article\n","permalink":"http://localhost:1313/posts/variational-autoencoders-for-feature-detection-of-magnetic-resonance-imaging-data/","tags":["Paper","Publications"],"title":"Variational Autoencoders for Feature Detection of Magnetic Resonance Imaging Data"}]